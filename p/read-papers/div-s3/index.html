<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Div-S3 is a non-learning approach to retrieve in-context exemplars from a large unlabeled dataset."><title>ã€è¯»è®ºæ–‡ã€‘An End-to-End Submodular Framework for Data-Efficient In-Context Learning</title>
<link rel=canonical href=https://blog.furffisite.link/p/read-papers/div-s3/><link rel=stylesheet href=/scss/style.min.1d9acc6d7417da29e26c03e15654a8a97a1eb01eaece9c154c7b2b3721fec799.css><meta property='og:title' content="ã€è¯»è®ºæ–‡ã€‘An End-to-End Submodular Framework for Data-Efficient In-Context Learning"><meta property='og:description' content="Div-S3 is a non-learning approach to retrieve in-context exemplars from a large unlabeled dataset."><meta property='og:url' content='https://blog.furffisite.link/p/read-papers/div-s3/'><meta property='og:site_name' content='Furffiblog'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='æœºå™¨å­¦ä¹ '><meta property='article:tag' content='è¯»è®ºæ–‡'><meta property='article:tag' content='ç»„åˆä¼˜åŒ–'><meta property='article:tag' content='ä¸Šä¸‹æ–‡å­¦ä¹ '><meta property='article:published_time' content='2024-07-08T12:33:03+08:00'><meta property='article:modified_time' content='2024-07-08T12:33:03+08:00'><meta property='og:image' content='https://files.furffisite.link/blogimg/20240709193826-409d3c5c4adf797af0b0d55992852fce-5194f.jpg'><meta name=twitter:title content="ã€è¯»è®ºæ–‡ã€‘An End-to-End Submodular Framework for Data-Efficient In-Context Learning"><meta name=twitter:description content="Div-S3 is a non-learning approach to retrieve in-context exemplars from a large unlabeled dataset."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://files.furffisite.link/blogimg/20240709193826-409d3c5c4adf797af0b0d55992852fce-5194f.jpg'><link rel=preconnect href=https://files.furffisite.link crossorigin><link rel=preconnect href=https://gfonts.aby.pub crossorigin><script async src=https://analytics.umami.is/script.js data-website-id=b3257363-e219-4eac-b59d-d75b9aba64b5></script><link href=https://files.furffisite.link/fontcache/NotoSansSC_Mulish_remote.min.css rel=preload as=style><link href=https://gfonts.aby.pub/s/mulish/v13/1Ptyg83HX_SGhgqO0yLcmjzUAuWexZNR8aevGw.woff2 rel=preload as=font><style>:root{--zh-font-family:"Noto Sans SC", "PingFang SC", "Hiragino Sans GB", "Droid Sans Fallback", "Microsoft YaHei";--base-font-family:"Mulish", var(--sys-font-family), var(--zh-font-family), sans-serif}</style></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=åˆ‡æ¢èœå•>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu8a7a5e24c6afd9e1fde1d549095c0023_459346_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ—‘ï¸</span></figure><div class=site-meta><h1 class=site-name><a href=/>Furffiblog</a></h1><h2 class=site-description>éšä¾¿å†™å†™</h2></div></header><ol class=menu-social><li><a href=https://github.com/furffico target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>ä¸»é¡µ</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>å…³äº</span></a></li><li><a href=/gallery/><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 32 32"><g fill="none"><path d="M3 7a4 4 0 014-4h14a4 4 0 014 4v14a4 4 0 01-4 4H7a4 4 0 01-4-4V7zm4-2A2 2 0 005 7v14a2 2 0 00.077.552l7.32-6.914c.9-.85 2.306-.85 3.205.0l7.32 6.914A2 2 0 0023 21V7a2 2 0 00-2-2H7zm0 18h14c.166.0.328-.02.482-.058l-7.253-6.85a.333.333.0 00-.458.0l-7.253 6.85c.155.038.316.058.482.058zm11.5-11a1.5 1.5.0 100-3 1.5 1.5.0 000 3zm-8 16.5a3.998 3.998.0 01-3.465-2H21a5.5 5.5.0 005.5-5.5V7.035c1.196.692 2 1.984 2 3.465V21A7.5 7.5.0 0121 28.5H10.5z" fill="currentcolor"/></g></svg>
<span>ç›¸å†Œ</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>æ–‡ç« å½’æ¡£</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>æœç´¢</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>æš—è‰²æ¨¡å¼</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">ç›®å½•</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#basic-information>Basic Information</a></li><li><a href=#the-problem-to-solve>The Problem to Solve</a></li><li><a href=#the-proposed-algorithm>The Proposed Algorithm</a><ol><li><a href=#exemplar-annotation>Exemplar Annotation</a></li><li><a href=#exemplar-retrieval>Exemplar Retrieval</a><ol><li><a href=#phase-1-of-s3>Phase 1 of S3</a></li><li><a href=#phase-2-of-s3>Phase 2 of S3</a></li></ol></li></ol></li><li><a href=#comments>Comments</a></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/read-papers/div-s3/><img src=https://files.furffisite.link/blogimg/20240709193826-409d3c5c4adf797af0b0d55992852fce-5194f.jpg loading=lazy alt="Featured image of post ã€è¯»è®ºæ–‡ã€‘An End-to-End Submodular Framework for Data-Efficient In-Context Learning"></a><div class=image-copyright><span>Photo by <a class=link href=https://unsplash.com/@rutzsepp target=_blank rel=noopener>Sepp Rutz</a> on <a class=link href=https://unsplash.com/photos/waterfall-between-trees-covered-with-snow-aF5Fpc5nY5s target=_blank rel=noopener>Unsplash</a></span></div></div><div class=article-details><header class=article-category><a href=/categories/%E7%AC%94%E8%AE%B0/>ç¬”è®°</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/read-papers/div-s3/>ã€è¯»è®ºæ–‡ã€‘An End-to-End Submodular Framework for Data-Efficient In-Context Learning</a></h2><h3 class=article-subtitle>Div-S3 is a non-learning approach to retrieve in-context exemplars from a large unlabeled dataset.</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jul 08, 2024</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>é˜…è¯»æ—¶é•¿: 4 åˆ†é’Ÿ</time></div></footer></div></header><section class=article-content><p>This blog post is completely written in English, just for practicing my English writing skills. Please let me know if there is any suggestions.</p><hr><h2 id=basic-information>Basic Information</h2><ul><li>Titleï¼š <strong>An End-to-End Submodular Framework for Data-Efficient In-Context Learning</strong> <sup><a id=ref-cite1-1 href=#cite1>[1]</a></sup></li><li>Authorsï¼š Lilly Kumari, Shengjie Wang, Arnav Das, Tianyi Zhou, Jeff Bilmes</li><li>Conferenceï¼š <a class=link href=https://2024.naacl.org/ target=_blank rel=noopener>NAACL 2024</a></li><li>Open Accessï¼š <a class=link href=https://aclanthology.org/2024.findings-naacl.209 target=_blank rel=noopener>https://aclanthology.org/2024.findings-naacl.209</a></li></ul><h2 id=the-problem-to-solve>The Problem to Solve</h2><p><strong>The problem of annotating, selecting and ordering in-context exemplars for Large Language Models (LLMs).</strong></p><p>The In-Context Learning (ICL) performance of LLMs is largely affected by the selection and ordering of in-context exemplars, which makes it necessary to develop a methodology to select the in-context exemplars according to the query.</p><h2 id=the-proposed-algorithm>The Proposed Algorithm</h2><p>In reality, the most of the data we have are unannotated data, <em>i.e.</em> queries without answers, some recent methods <sup><a id=ref-cite2-1 href=#cite2>[2]</a></sup> suggest to select and annotate a subset from an unannotated huge dataset
$\mathcal X_\mathrm{unlabeled}$ to form a small annotated dataset $\mathcal X_\mathrm{labeled}$, and to choose the in-context exemplars from this subset during evaluation. This passage followed this paradigm, and proposed <strong>Div-S3</strong>, a two-stage data-efficient learning-free framework for exemplar selection.</p><ul><li>The first stage (<strong>Div</strong>): Exemplar Annotation, from $\mathcal X_\mathrm{unlabeled}$ to $\mathcal X_\mathrm{labeled}$.</li><li>The second stage (<strong>S3</strong>): Exemplar Retrieval, from $\mathcal X_\mathrm{labeled}$ and query set $Q$ to get in-context exemplars $\mathcal D_\mathrm{context}$.</li></ul><h3 id=exemplar-annotation>Exemplar Annotation</h3><p><strong>Problem Definition.</strong>
The first stage of <em>Div-S3</em>, as mentioned above, selects from unannotated data $\mathcal X_\mathrm{unlabeled}$ and let <em>homo sapiens</em> do the annotations to make an informative and diverse subset $\mathcal X_\mathrm{labeled}$, with the constraint of $|\mathcal X_\mathrm{labeled}| \ll |\mathcal X_\mathrm{unlabeled}|$. This is a process similar to one iteration of pool-based active learning. With the objective of diversity and reducing redundancy, this can also be formulated as a set optimization problem <sup><a id=ref-cite3-1 href=#cite3>[3]</a></sup> as follows:
$$\max_{A\subset \mathcal X_\mathrm{unlabeled},|A|\le k} f(A),$$
where $k$ is a hyperparameter representing the annotation budget, $f:~2^{\mathcal X_\mathrm{unlabeled}}\rightarrow\mathbb R$ is a submodular function mapping all subsets of $\mathcal X_\mathrm{unlabeled}$ to the respective score of each subset. The higher the score, the better the subset is.</p><blockquote><p>The submodular function must satisfy the properties of monotone and decreasing marginal profit, <em>i.e.</em>, respectively,
$$\begin{aligned}\forall A\subseteq T, \quad&amp;f(A) \le f(T), \\ \forall A\subset T,~ \forall x\not\in T, \quad&amp;f(\{x\}|A) \ge f(\{x\}|T), \end{aligned}$$
where $f(\{x\}|T) = f(\{x\}\cup T) - f(T)$ is the marginal profit of adding $\{x\}$ to $T$.</p></blockquote><p>The authors set the submodular function to be <em>facility location</em>, which is defined as
$$f(A) = \sum_{s_i\in\mathcal X_\mathrm{unlabeled}}\max_{s_j\in A}\mathrm{sim}(s_i,s_j),$$
where $\mathrm{sim}(\cdot,\cdot)$ denotes the cosine similarity of two queries&rsquo; embeddings, generated by sentence-BERT <sup><a id=ref-cite4-1 href=#cite4>[4]</a></sup>.</p><p><strong>Intuitive Interpretation.</strong>
This problem can be intuitively and geometrically interpreted as minimizing the sum of all distances between each node and its nearest selected nodes, which is a k-medoids problem and is pretty similar to k-means clustering.</p><p><strong>Solution.</strong>
The authors of this paper use a greedy algorithm proposed by Nemhauser <em>et al.</em> <sup><a id=ref-cite5-1 href=#cite5>[5]</a></sup>, called Greedy Submodular Maximization (GSM). Its fundamental idea is to greedily select the item with the maximum marginal profit for $k$ iterations, <em>i.e.</em>
$$A\leftarrow A\cup \{\argmax_{v\in V, v\not\in A} f(A\cup \{v\}) - f(A) \}.$$
Considering the time spent in calculating $f$, this is an algorithm with the time complexity of $O((nk)^2)$. The paper says it&rsquo;s $O(n^2+nk)$ but I beg to differ as it seems to have ignored the time complexity of calculating $f$, which is $\Theta(nm)$ with pre-calculated similarity matrix, where $m=0,1,\ldots,k-1$ in the iterations. But I agree with the authors that the algorithm can be accelerated by techniques like caching and priority queues, <em>etc.</em></p><h3 id=exemplar-retrieval>Exemplar Retrieval</h3><p>Exemplar retrieval is intended to find the best in-context exemplars $\mathcal D_\mathrm{context}$ for the given query set $Q$ from $\mathcal X_\mathrm{labeled}$. Previous similarity-based methods usually yield in-context exemplars with redundant information. To reduce such redundancy, the authors formalize exemplar retrieval as a conditional submodular subset selection problem. The purpose of this stage is to &ldquo;obtain a set of exemplars that are not only relevant to the test query but also encompass diverse aspects crucial for aiding the LLM in the target task&rdquo; <sup><a id=ref-cite1-2 href=#cite1>[1]</a></sup>. They come up with a two-phase method called Submodular Span Summarization (S3), which was published prior to this paper <sup><a id=ref-cite6-1 href=#cite6>[6]</a></sup>.</p><h4 id=phase-1-of-s3>Phase 1 of S3</h4><p><strong>Problem Definition.</strong>
This phase targets to select a relatively large subset relevant to the query set $Q$, but might be redundant.
The original problem might be difficult to solve, so the paper considered solving the dual problem of it:
$$\min_{A\subseteq V - Q,|A|\ge k_1}f(A|Q),$$
which is a cardinality-constrained submodular minimization problem. The authors use $m_Q(A) = \sum_{a\in A}f(a|Q)$ to approximate $f(A|Q)$, which is an upper bound of $f(A|Q)$.</p><p><strong>Solution.</strong>
Although the paper doesn&rsquo;t state it clearly, I think the algorithm to solve this problem, given the approximation, is to select $k_1$ exemplars with minimal values of $f(a|Q)$ from $A$. And this algorithm matches the time complexity $O(k+k\log k_1)$ stated in Appendix B, if ignoring the time for calculating $f$.</p><h4 id=phase-2-of-s3>Phase 2 of S3</h4><p>This stage is intended to select the most representative exemplars from the result of phase 1, and is mathematically the same as <a class=link href=#exemplar-annotation>Exemplar Annotation</a>:
$$\max_{A\subset A_Q,|A|\le k_2} f(A),$$
where $A_Q$ is the set of selected exemplars from phase 1.
Optionally, we can apply a knapsack constraint on the problem, and solve it with a modified version of GSM.</p><h2 id=comments>Comments</h2><p>The authors proposed a learning-free framework named <strong>Div-S3</strong> to select in-context exemplars from unlabeled datasets, and evaluated its effectiveness with ablation experiments across 7 Natural Language Processing (NLP) tasks and 5 LLMs. Although the algorithm doesn&rsquo;t take ordering into consideration, the paper proves its insensitiveness to the order of exemplars.</p><p>However, from my perspective, I still have some problems related to the paper:</p><ul><li>In Exemplar Retrieval stage, what&rsquo;s the meaning of computing $f(Q)$ against all unlabeled data $\mathcal X_\mathrm{unlabeled}$. Given that $\mathcal X_\mathrm{labeled}$ is a representative subset of $\mathcal X_\mathrm{unlabeled}$, would it be computationally better to calculate $f(Q)$ and $f(a|Q)$ only against $\mathcal X_\mathrm{labeled}\cup Q$?</li><li>What&rsquo;s the purpose of dealing with the queries as a whole (query set $Q$), instead of retrieving the best exemplars for each query $q$?</li><li>The experiments didn&rsquo;t cover the comparison of Div-S3 with some recent algorithms, especially the learning-based ones.</li><li>Will the algorithm averagely perform better if we handcraft a rule to arrange the selected exemplars? Also, in Figure 3, the variances do not seem to be small.</li></ul><h2 id=references>References</h2><style>.bibliography{display:table;font-size:medium;line-height:normal}.bib-item{display:table-row}.bib-item>:first-child{display:table-cell;padding-right:.5em;font-weight:700;text-align:right}.bib-item>:last-child{display:table-cell;padding-bottom:.5ex}</style><div class=bibliography><div id=cite1 class=bib-item><span>[1]</span>
<span>L. Kumari, S. Wang, A. Das, T. Zhou, and J. Bilmes, â€œAn End-to-End Submodular Framework for Data-Efficient In-Context Learning,â€ in Findings of the Association for Computational Linguistics: NAACL 2024, K. Duh, H. Gomez, and S. Bethard, Eds., Mexico City, Mexico: Association for Computational Linguistics, Jun. 2024, pp. 3293â€“3308. Accessed: Jul. 02, 2024. [Online]. Available: <a class=link href=https://aclanthology.org/2024.findings-naacl.209 target=_blank rel=noopener>https://aclanthology.org/2024.findings-naacl.209</a><a href=#ref-cite1-1>â¤¶</a><a href=#ref-cite1-2>â¤¶</a></span></div><div id=cite2 class=bib-item><span>[2]</span>
<span>H. Su et al., â€œSelective Annotation Makes Language Models Better Few-Shot Learners,â€ presented at the The Eleventh International Conference on Learning Representations, Sep. 2022. Accessed: May 30, 2024. [Online]. Available: <a class=link href="https://openreview.net/forum?id=qY1hlv7gwg" target=_blank rel=noopener>https://openreview.net/forum?id=qY1hlv7gwg</a><a href=#ref-cite2-1>â¤¶</a></span></div><div id=cite3 class=bib-item><span>[3]</span>
<span>S. C. H. Hoi, R. Jin, J. Zhu, and M. R. Lyu, â€œBatch mode active learning and its application to medical image classification,â€ in Proceedings of the 23rd international conference on Machine learning, in ICML â€™06. New York, NY, USA: Association for Computing Machinery, Jun. 2006, pp. 417â€“424. doi: 10.1145/1143844.1143897.<a href=#ref-cite3-1>â¤¶</a></span></div><div id=cite4 class=bib-item><span>[4]</span>
<span>N. Reimers and I. Gurevych, â€œSentence-BERT: Sentence Embeddings using Siamese BERT-Networks.â€ arXiv, Aug. 27, 2019. Accessed: Jul. 08, 2024. [Online]. Available: <a class=link href=http://arxiv.org/abs/1908.10084 target=_blank rel=noopener>http://arxiv.org/abs/1908.10084</a><a href=#ref-cite4-1>â¤¶</a></span></div><div id=cite5 class=bib-item><span>[5]</span>
<span>G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher, â€œAn analysis of approximations for maximizing submodular set functionsâ€”I,â€ Mathematical programming, vol. 14, pp. 265â€“294, 1978.<a href=#ref-cite5-1>â¤¶</a></span></div><div id=cite6 class=bib-item><span>[6]</span>
<span>L. Kumari and J. Bilmes, â€œSubmodular Span, with Applications to Conditional Data Summarization,â€ Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 14, Art. no. 14, May 2021, doi: 10.1609/aaai.v35i14.17465.<a href=#ref-cite6-1>â¤¶</a></span></div></div></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>æœºå™¨å­¦ä¹ </a>
<a href=/tags/%E8%AF%BB%E8%AE%BA%E6%96%87/>è¯»è®ºæ–‡</a>
<a href=/tags/%E7%BB%84%E5%90%88%E4%BC%98%E5%8C%96/>ç»„åˆä¼˜åŒ–</a>
<a href=/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>ä¸Šä¸‹æ–‡å­¦ä¹ </a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>æœ¬æ–‡åŸºäº<a class=link href=https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode.zh-Hans target=_blank rel=noopener><u>CC BY-NC-SA 4.0 åè®®</u></a>å‘å¸ƒã€‚æœ¬æ–‡<strong>ä¸å¯å•†ç”¨</strong>ï¼Œè½¬è½½æ—¶è¯·<strong>æ³¨æ˜å‡ºå¤„</strong>å¹¶ä½¿ç”¨<strong>ç›¸åŒåè®®</strong>ã€‚</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>ç›¸å…³æ–‡ç« </h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/read-papers/utsp/><div class=article-image><img src=https://files.furffisite.link/blogimg/20240312193735-df25ede3714c69d2ea8b42ba9c39f7c9-755f3.jpg loading=lazy data-key=read-papers/utsp data-hash=https://files.furffisite.link/blogimg/20240312193735-df25ede3714c69d2ea8b42ba9c39f7c9-755f3.jpg></div><div class=article-details><h2 class=article-title>ã€è¯»è®ºæ–‡ã€‘Unsupervised Learning for Solving the Travelling Salesman Problem</h2></div></a></article><article class=has-image><a href=/p/deep-q-learning/><div class=article-image><img src=https://files.furffisite.link/blogimg/20230822110113-5ef18ab6cfb63d5a730bbd8e077231e7-6ba69.jpg loading=lazy data-key=deep-Q-learning data-hash=https://files.furffisite.link/blogimg/20230822110113-5ef18ab6cfb63d5a730bbd8e077231e7-6ba69.jpg></div><div class=article-details><h2 class=article-title>ã€RLå­¦ä¹ ç¬”è®°ã€‘æ·±åº¦Qå­¦ä¹ ç®—æ³•ä¸ç»éªŒå›æ”¾</h2></div></a></article><article class=has-image><a href=/p/q-learning/><div class=article-image><img src=https://files.furffisite.link/blogimg/20230518191643-b6c8849bfb006d40abef7203bb5e15a0-18b9a.jpg loading=lazy data-key=Q-learning data-hash=https://files.furffisite.link/blogimg/20230518191643-b6c8849bfb006d40abef7203bb5e15a0-18b9a.jpg></div><div class=article-details><h2 class=article-title>ã€RLå­¦ä¹ ç¬”è®°ã€‘Qå­¦ä¹ ç®—æ³•</h2></div></a></article><article class=has-image><a href=/p/windows-setup/><div class=article-image><img src=https://files.furffisite.link/blogimg/20240707215654-5c276c9ae1c98340521bf56811f4b765-87c36.jpg loading=lazy data-key=windows-setup data-hash=https://files.furffisite.link/blogimg/20240707215654-5c276c9ae1c98340521bf56811f4b765-87c36.jpg></div><div class=article-details><h2 class=article-title>ä¸ªäººå¸¸ç”¨çš„æ–° Windows 11 ç³»ç»Ÿçš„é…ç½®è¿‡ç¨‹</h2></div></a></article><article class=has-image><a href=/p/applemusic-transfer/><div class=article-image><img src=https://files.furffisite.link/blogimg/20240523203808-9f4a7d937672d53fbc1a7174037c6f64-581fc.jpg loading=lazy data-key=applemusic-transfer data-hash=https://files.furffisite.link/blogimg/20240523203808-9f4a7d937672d53fbc1a7174037c6f64-581fc.jpg></div><div class=article-details><h2 class=article-title>Apple Music æ›²åº“è¿ç§»</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=Furffico/Furffico.github.io data-repo-id=R_kgDOIs6c3Q data-category=General data-category-id=DIC_kwDOIs6c3c4CTWXf data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark_dimmed")}})()</script><footer class=site-footer><section class=copyright>&copy;
2022 -
2024 Furffiblog</section><section class=powerby>ä½¿ç”¨ <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> æ„å»º<br>ä¸»é¢˜ <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.26.0>Stack</a></b> ç”± <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> è®¾è®¡</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://files.furffisite.link/fontcache/NotoSansSC_Mulish_remote.min.css",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>