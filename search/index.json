[{"content":"验机 在完成 Windows 初始配置，进入桌面后的第一件事是验机，即确保笔记本的配置符合厂家的宣传、确保笔记本没有暗病等。\n在外观上的验机步骤在开机前应当已经完成了，例如包装正常、外观无划痕、首次开机必须接入电源等。 但是，我们并不能从外观看出笔记本的配置信息，因此，需要在进入系统后使用相关软件检测笔记本的硬件配置。这些工具例如：\nCPU-Z：检测主要硬件信息（CPU/主板/内存显卡）； AIDA-64：检测所有硬件信息； CrystalDiskInfo: 查看硬盘信息和状态； …… 这类工具软件都已经被DIY爱好者中著名的图吧工具箱和卡硬工具箱收录，所以也可以直接下载使用这些工具箱用于检测硬件。 对于办公用的笔记本而言这些验机软件是无用的，因此较为推荐的做法是将其程序放在 U 盘里，验新机的时候只需插入这个 U 盘，运行这些程序即可。\n清理 对于新系统而言，需要清理的只有预装软件和开机启动项\n清理预装软件：右键 Windows 徽标 -\u0026gt; “安装的应用” -\u0026gt; 遍历列表并卸载用不上的预装应用； 清理开机启动项：右键 Windows 徽标 -\u0026gt; “任务管理器” -\u0026gt; 启动应用 -\u0026gt; 遍历列表并卸载用不上的预装应用。 设置 Windows 硬盘分区 因为有些品牌的笔记本出厂是自带 BitLocker 分区加密的，而常用的 DiskGenius 等第三方的分区助手似乎并不支持 BitLocker 加密的分区，所以我这里使用 Windows 自带的硬盘管理功能管理硬盘分区。 Windows 的硬盘管理功能可以直接通过 Windows 徽标的右键菜单打开。\n在“磁盘管理”中，使用 右键 -\u0026gt; 删除卷 删除出厂预分配的带盘符的分区（不带盘符的恢复分区最好别删），然后使用右键 Windows 分区 -\u0026gt; 扩展卷或者压缩卷，以调整 Windows 分区的大小。我订购的笔记本内置了一块 1 TB 的固态硬盘，我的空间分配方案如下：\nWindows 分区（300 GiB），用于存放 Windows 系统、应用程序和开发环境； Data 分区（200 GiB），用于存放学习资料、代码和照片等数据； Extra 分区（剩余的 451 GiB），用于存放可以从互联网重复下载的资源，例如 Steam 游戏库、预训练模型权重和数据集等。 这里没有给 Linux 系统留空间是因为新的笔记本内有一个空的 M.2 NVME 硬盘位，我准备把旧笔记本内的固态硬盘拆了放在这里作为 Linux 系统的系统盘。\n开始菜单 清理开始菜单：点击 Windows 徽标打开开始菜单 -\u0026gt; 删除开始菜单内不需要的应用图标 展示更多项目：进入设置 -\u0026gt; “个性化” -\u0026gt; “开始” -\u0026gt; 选择“更多固定项” 管理电源按钮左侧的图标：进入设置 -\u0026gt; “个性化” -\u0026gt; “开始” -\u0026gt; “文件夹” -\u0026gt; 开启需要显示在电源按钮左侧的图标（我选择了设置、文件资源管理器、下载和个人文件夹） 任务栏 任务栏居左：进入设置 -\u0026gt; “个性化” -\u0026gt; “任务栏” -\u0026gt; “任务栏行为” -\u0026gt; “任务栏对齐方式” -\u0026gt; “靠左” 搜索框改为搜索图标：\u0026hellip; -\u0026gt; “任务栏” -\u0026gt; “任务栏项” -\u0026gt; “搜索” -\u0026gt; “仅搜索图标” 关闭小组件：\u0026hellip; -\u0026gt; “任务栏项” -\u0026gt; “小组件” -\u0026gt; 设为关闭 鼠标指针样式 个人认为默认的白色指针不好看，并且在白底黑字、文字和指针大小相近的情况下，有时会混进文字里难以分辨。\n更改鼠标指针样式：进入设置 -\u0026gt; “辅助功能” -\u0026gt; “鼠标指针与触控” -\u0026gt; “鼠标指针样式” -\u0026gt; 我个人更喜欢第四项 “自定义” -\u0026gt; 从给出的颜色中选一个（不满意的话也可以选择其它颜色） 语言 添加英文输入法（便于写代码）：进入设置 -\u0026gt; “时间和语言” -\u0026gt; “语言和区域” -\u0026gt; “添加语言” -\u0026gt; 搜索并选择“英语（美国）” 添加日文输入法（有时会用到）：\u0026hellip; -\u0026gt; “添加语言” -\u0026gt; 搜索并选择“日语” 个人数据存储位置 这一步的目的是将一部分个人数据的保存位置从系统盘更改至 D 盘。不过这个操作只能迁移一部分数据，对于 AppData 内的文件则无能为力。\n进入个人文件夹 -\u0026gt; 右键“文档/音乐/图片/视频/下载” -\u0026gt; “属性” -\u0026gt; “位置”标签页 -\u0026gt; 点击“移动” -\u0026gt; 选择 D 盘内的目标文件夹 -\u0026gt; “确定” 进入设置 -\u0026gt; “系统” -\u0026gt; “存储” -\u0026gt; “保存新内容的地方” -\u0026gt; 将中间四项的存储位置从 C 盘更改为 D 盘 安装软件 工具 目前只安装了这些，我在之后发现的和用到的好用小工具也会更新到这个列表里。\nPowerToys (Microsoft Store)：开源的 Windows 小工具合集； Snipaste (Microsoft Store)：截图/贴图工具； Notepads App (Microsoft Store)：更美观的记事本平替； PotPlayer (Microsoft Store)：媒体播放器； Bandizip (Microsoft Store)：好用的压缩软件； Sumatra PDF (Download)：轻量级 PDF 阅读器； Zotero (Download)：文献管理/阅读工具； MacType：Windows 字体渲染优化。 开发环境 后续我主要的开发工作还是会在 Linux 系统中进行，因此在 Windows 系统里只装这些应该就够了。\nVisual Studio Code：代码编辑器； Python：Python 解释器； Scoop：Windows 的第三方包管理工具； 1 2 Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser Invoke-RestMethod -Uri https://get.scoop.sh | Invoke-Expression Git + hugo：版本管理 + 写博客用的。 1 scoop install git go ","date":"2024-07-05T10:57:02+08:00","image":"https://files.furffisite.link/blogimg/20240707215654-5c276c9ae1c98340521bf56811f4b765-87c36.jpg","permalink":"https://blog.furffisite.link/p/windows-setup/","title":"个人常用的新 Windows 11 系统的配置过程"},{"content":"背景 刚上大学的时候，我考虑到日区的 Apple Music 版本可选的歌曲更多，而且各种服务也更给力[1]。 于是我就开通了日区的会员，因为有学生优惠，每月也就花 580 日元（约 25 人民币）。 但现在毕业在即，我开始怀疑我到研究生阶段还能不能继续享受这个优惠。而日区会员原价要每月 1080 日元（约 50 人民币），这超出我的可接受范围了。 此外，最近淘宝上苹果日区 App Store 的充值卡不是很好找，而我日区账户的余额也要见底了。 所以，是时候换个平台了。\n然而，国内的音乐平台的社交属性太强，我个人不太喜欢这些，觉得太热闹了[2]。 相对而言，Apple Music 则更专注于音乐本身，而且跟苹果生态融合的更好，所以我最后还是选择了转到 Apple Music 的中国大陆区（国区）。\n我有两个苹果账户，一个在国区、一个在日区，于我而言这里的“转区”就是将后者资料库的所有歌曲添加到前者的资料库中。 考虑到 Apple Music 国区的版权库不如日区，我并不要求将其全部迁移，只要能将大部分歌曲复制到目标账户的资料库里就行。\n我能搜到的成熟的工具不是满足不了我的需求就是需要收费，因此我决定自己探索迁移曲库的方法。本文的方法分为两步：\n从源账户获取歌曲 将歌曲添加到新账户 这需要操作者有一定的编程和爬虫基础，本文只是讲述我的思路和操作流程，我也没有将其整理成通用的代码的想法，文中的脚本需要根据实际情况修改后才可以正常使用。 本文的方法与账户所在的区域无关，因此理论上也适用于其它区域间的和相同区域不同账户之间的迁移。\n第一步：从源账户获取歌曲 我积累了四年的账户里有歌曲 8441 首，它们分布在 1820 张专辑内，所以以专辑为单位迁移更合理一些。\n得益于 Apple Music 的网页端，获取相关的 API 并不是什么难事：\n在浏览器内的 Apple Music网页端登录源账户，打开调试工具，切换到 Network 页，过滤出 XHR 请求。 点击“专辑/Albums”切换到专辑页，这时在调试工具内应该会出现一条 amp-api 开头的请求： 右键这条请求，Copy -\u0026gt; Copy as cURL，复制到终端内尝试重放请求，在我这里成功了，说明苹果并没有做各种弯弯绕绕的反爬措施，好评。 这个API响应的结构大致如下：\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;data\u0026#34;: [...], \u0026#34;resources\u0026#34;: { \u0026#34;library-albums\u0026#34;: {...}, \u0026#34;albums\u0026#34; : {...}, \u0026#34;library-artists\u0026#34;: {...}, \u0026#34;artists\u0026#34;: {...} }, \u0026#34;meta\u0026#34;: {...} } 有了 API 之后就可以循环请求获取完整列表了：\n请求参数里的 offset 项指定了偏移量，通过不断改变这个值可以获取完整的专辑列表。 在响应json最后的 meta 项里有订阅的专辑总数，在我这里是 \u0026quot;meta\u0026quot;: {\u0026quot;total\u0026quot;: 1820, ...}，即1820条，请求参数内 limit=100 也就是每页有 100 条。根据这两个数值可以算出一共有 19 页，要请求 19 次。我也尝试了调高 limit，发现 limit\u0026gt;100 时 API 会返回错误。 将前面复制的 curl 指令放到 .sh 脚本内，写一个循环，例如： 1 2 3 4 5 6 7 8 9 10 11 ...... for i in {0..18}; do chunk=\u0026#34;${i}00\u0026#34; curl \u0026#34;https://amp-api.music.apple.com/.../...\u0026amp;offset=$chunk\u0026amp;...\u0026#34; \\ --compressed \\ ...... -H \u0026#39;Sec-Fetch-Site: same-site\u0026#39; \\ -H \u0026#39;TE: trailers\u0026#39; \\ -o \u0026#34;chunk$chunk.json\u0026#34; # 把响应输出到文件 sleep 10 # 避免请求间隔太短导致被 ban done 在终端用 bash 运行这个脚本，不一会资料库内的所有专辑的信息就都被保存到本地的 json 文件内了。 第二步：将歌曲添加到新账户 和上面类似，首先获取添加专辑的 API：\n切换到目标账户，打开调试工具，切换到 Network 页，过滤出 XHR 请求。 在首页上随便找个专辑添加到资料库内，在调试工具内定位到这条请求： 同上，复制 curl 指令到终端内尝试重放，成功。 分析请求 URL：\n1 https://amp-api.music.apple.com/v1/me/library?art[url]=f\u0026amp;format[resources]=map\u0026amp;ids[albums]=1725057905\u0026amp;representation=ids 其中的 1725057905 对应之前获取到的 json 文件里 resources.albums 内的每个属性的名称，也就是每个专辑的 ID。 由于 URL 内 ID 是复数 ids，我便猜测能否同时添加多个专辑，将URL中的 1725057905 替换为 398320584,322934943，重新发送请求，居然也成功了，说明我的猜测是对的。\n有了这些基础，编写脚本就很容易了，首先使用 jq 解析之前保存的响应 json，提取出其中 resources.albums 内每一项的键值，使用逗号分隔输出并拼接到 url 内：\n1 2 3 jqs=\u0026#34;.resources.albums | keys[${section}] | [ .[] | tonumber ] | @csv\u0026#34; ids=\u0026#34;$(cat chunk${index}00.json | jq -r \u0026#34;$jqs\u0026#34; )\u0026#34; url=\u0026#34;https://amp-api.music.apple.com/.../...\u0026amp;ids%5Balbums%5D=$ids\u0026amp;...\u0026#34; 放到之前的 curl 请求内，加上循环组成脚本，脚本里对每个 chunk 分段请求是因为一次增加 100 张专辑请求的响应会很慢：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ...... for index in {0..18}; do for section in \u0026#39;:25\u0026#39; \u0026#39;25:50\u0026#39; \u0026#39;50:75\u0026#39; \u0026#39;75:\u0026#39;; do jqs=\u0026#34;.resources.albums | keys[${section}] | [ .[] | tonumber ] | @csv\u0026#34; ids=\u0026#34;$(cat chunk${index}00.json | jq -r \u0026#34;$jqs\u0026#34; )\u0026#34; url=\u0026#34;https://amp-api.music.apple.com/v1/me/library?art%5Burl%5D=f\u0026amp;format%5Bresources%5D=map\u0026amp;ids%5Balbums%5D=$ids\u0026amp;representation=ids\u0026#34; curl -X POST \u0026#34;$url\u0026#34; \\ -H \u0026#34;$ua\u0026#34; \\ -H \u0026#39;Accept: */*\u0026#39; \\ ...... -H \u0026#39;Content-Length: 0\u0026#39; \\ -H \u0026#39;TE: trailers\u0026#39; echo sleep 10 # 避免请求间隔太短导致被 ban done done 之后运行这个脚本，就可以看到自己源账户里的歌曲被慢慢添加到目标账户里了。\n哪些歌曲没成功迁移 仿照第一步获取目标账户的所有专辑，然后写一些脚本就能看到有哪些歌曲没被成功迁移了，例如这个 python 程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 import json def getalbums(count: int, fn: str) -\u0026gt; dict: albums = {} for index in range(count): filename = fn.format(index) data = json.load(open(filename)) for k,v in data[\u0026#34;resources\u0026#34;][\u0026#34;albums\u0026#34;].items(): albums[int(k)] = v[\u0026#34;attributes\u0026#34;][\u0026#34;name\u0026#34;] + \u0026#39; | \u0026#39; + v[\u0026#34;attributes\u0026#34;][\u0026#34;artistName\u0026#34;] return albums org_album = getalbums(19, \u0026#34;chunk{}00.json\u0026#34;) dest_album = getalbums(15, \u0026#34;after-chunk{}00.json\u0026#34;) ids = set(org_album) - set(dest_album) for i in ids: print(f\u0026#34;{i}:\u0026#34;,org_album[i]) print(len(ids)) 我一共有 338 张专辑没有被成功迁移，这主要有三种情况：\nApple Music 国区没版权； 没有一模一样的，但是有不同版本的； 国区和日区都有，但是 ID 不同，例如 RADWIMPS 和 HOYO-MiX 的专辑。 其中后两者靠手动搜索也可以慢慢添加回去，如果遇到了第一种那就真的没办法了。\n参考资料 [1] 订阅 Apple Music 该选哪个区？——中美坡港台日六大地区全对比（第二版） - 向远公园 | Step Park⤶ [2] 音乐平台横评：Apple Music、QQ 音乐、网易云、咪咕、Spotify、YouTube Music、Tidal - 少数派⤶ ","date":"2024-05-23T16:01:12+08:00","image":"https://files.furffisite.link/blogimg/20240523203808-9f4a7d937672d53fbc1a7174037c6f64-581fc.jpg","permalink":"https://blog.furffisite.link/p/applemusic-transfer/","title":"Apple Music 曲库迁移"},{"content":"太长不看版：\n使用 root 权限打开 /etc/security/faillock.conf （vim 可换成其它编辑器，如 nano） 1 $ sudo vim /etc/security/faillock.conf 取消注释并修改unlock_time一项，60 可替换为你想要的秒数（默认600秒） 1 unlock_time = 60 或者，修改deny一项关闭错误锁定 1 deny = 0 背景 今天清晨我刚刚起床，在迷糊中想看看半夜挂机训练的模型的效果，于是抓起笔记本开机，输密码。结果因为我没睡醒，输错了三次密码，屏幕上跳出了这个提示：\n（登录界面的壁纸是 さなせ 老师画的 银狼。）\n哇！我用了一年多的 EndeavourOS 第一次见到这个提示。再怎么说输错三次要锁 10 分钟也太无情了吧，如果我急着用怎么办。怎么改变这个设置呢？\nfaillock 配置 由于我不知道这个部分具体是那个模块负责的，搜索的过程还是有一些波折的。在这个过程中，我发现登录界面（greeter）由 LightDM 的 greeter [1] 提供，登录验证由 Pluggable Authentication Modules (PAM) [2][3] 处理，账户锁定的部分则由 PAM 的模块pam_faillock.so负责。前者的配置文件在 /etc/lightdm/ 文件夹下，文件名视所使用的 greeter 而定（我这里是slick-greeter.conf），后者的配置文件是 /etc/security/faillock.conf[4].\n使用 vim、nano 等文本编辑器以 root 权限打开 faillock 的配置文件：\n1 $ sudo vim /etc/security/faillock.conf 可以发现默认的配置文件里（可能因发行版不同而有差异）已经解释了每一项配置及其作用，我们要做的只是取消对应行的注释，修改成我们想要的数值。\n账户锁定相关的配置 对于非共享的PC而言我觉得最重要的也就三项：deny，fail_interval和unlock_time。这三项用一句话来概括就是：“deny为0时无论输错多少次都不会锁定账户，否则，在{fail_interval}秒内连续密码错误{deny}次会导致账户被锁定{unlock_time}秒。”这三项的默认值分别是deny=3，fail_interval=900和unlock_time=600\n为了避免暴力破解，我没有将deny设为 0，以下是我的配置：\n1 2 3 deny = 3 fail_interval = 60 unlock_time = 60 因为比起默认的 10 分钟，1 分钟我觉得是兼顾了安全和便捷的选择。\n另外，faillock 记录的登录失败次数默认是放在 /var/run/faillock 内的，而这个文件夹处在临时文件系统 tmpfs 内，也就是说当账户因多次密码错误被锁定时，只要重启电脑就能解除锁定[5]。修改配置文件的dir一项，将文件夹改到持久存储的文件系统内即可防止重启解除锁定（例如/var/lib/faillock）。\n我还试了一下，在默认情况下使用 ssh 远程登陆也是有可能触发账户锁定的（当然这个也取决于PAM的配置），当账户锁定时即使密码正确也会返回 Permission denied, please try again.。\nroot 相关的配置 在默认情况下，为了防止 DOS 攻击， faillock 是不会锁定 root 账户的 [6]。开启 even_deny_root 这一项则让 faillock 可以锁定 root 。使用 root_unlock_time 可以为 root 账户单独设置锁定时间，并且设置这项会隐式开启even_deny_root。\n日志相关的配置 在命令行中使用：\n1 $ journalctl --since today -fg pam 可以看到今天以来与 PAM 有关的日志，使用 faillock 指令可以看到系统当前记录的登录失败的信息，例如：\n1 2 3 4 5 6 $ faillock --user furffico furffico: When Type Source Valid 2024-03-21 13:16:24 RHOST 192.168.1.101 V 2024-03-21 13:16:27 RHOST 192.168.1.101 V 2024-03-21 13:16:30 RHOST 192.168.1.101 V 配置文件内与日志相关的配置有三个：\naudit: 当用户不存在时将用户名记入系统日志。 1 2 3 4 # before: sshd[134004]: pam_faillock(sshd:auth): User unknown # after: sshd[136827]: pam_faillock(sshd:auth): User unknown: f slient：不打印 informative（信息丰富的？）消息（没试出来这个开了有什么区别）。 no_log_info：不向系统日志打印 informative 消息。 参考资料 [1] LightDM - ArchWiki⤶ [2] PAM - ArchWiki⤶ [3] An introduction to Pluggable Authentication Modules (PAM) in Linux | Enable Sysadmin⤶ [4] faillock.conf(5) — Arch manual pages⤶ [5] Security - ArchWiki⤶ [6] pam_faillock(8) — Arch manual pages⤶ ","date":"2024-03-20T13:55:32+08:00","image":"https://files.furffisite.link/blogimg/20240321144218-38a3404b3f78e405beab5627f4e45e7b-f5a7b.jpg","permalink":"https://blog.furffisite.link/p/linux-authfail-lock/","title":"【Linux】修改登录界面 密码三次错误锁定时间"},{"content":"论文信息 标题： Unsupervised Learning for Solving the Travelling Salesman Problem[1] 作者： Yimeng Min, Yiwei Bai, Carla P. Gomes 会议： NeurIPS 2023 在线资源： https://proceedings.neurips.cc/paper_files/paper/2023/hash/93b8618a9061f8a55825c13ecf28392b-Abstract-Conference.html 代码： https://github.com/yimengmin/UTSP UTSP 算法 作者认为理想的 heatmap $\\mathcal{H}\\in[0,1]^{n\\times n}$ 应该表示 TSP 的最优解，即一条长度最短的汉密尔顿环路，也就是：\n$\\mathcal{H}$ 作为邻接矩阵表示的图内有且仅有一条汉密尔顿环路； $\\mathcal{H}$ 表示的环路长度最短，即$$\\min_\\mathcal{H}\\sum^n_{i=1}\\sum^n_{j=1} \\mathcal{H} _{ij}\\cdot d _{ij}$$ 为了让网络输出的 $\\mathcal{H}$ 满足第一个条件，作者设计了 soft indicator matrix $\\mathbb{T}\\in[0,1]^{n\\times n}$，$\\mathbb{T}=[\\mathbf p_1|\\mathbf p_2|\\cdots|\\mathbf p_n]$ 是$n$个列向量组成的矩阵，满足各列和为$1$（$\\sum_{j=1}^n p_{ij} = 1$），这个条件可以使用 Softmax 函数或者归一化满足，论文里使用了前者。\n然后作者提出了 $\\mathbb{T}\\rightarrow\\mathcal{H}$ transformation，以将 soft indicator $\\mathbb{T}$ 转化为可以采样的 heatmap $\\mathcal{H}$：$$\\mathcal{H} = \\sum_{i=1}^n \\mathbf p_i\\cdot \\mathbf p_{i+1}^T + \\mathbf p_n\\cdot \\mathbf p_1^T$$ 同时作者也证明了这样形成的 heatmap 中至少有一条汉密尔顿环路，这样就满足了第一个条件的一半（有一条）。\n至于剩下的一半（不超过一条），作者使用设计的 loss 函数鼓励网络减少环路数量： $$\\mathcal{L}=\\lambda _1 \\sum^n _{i=1}(\\sum^n _{j=1}\\mathbb{T} _{ij}-1)^2 + \\lambda_2 \\sum^n _{i=1}\\mathcal{H} _{ii} + \\sum^n _{i=1}\\sum^n _{j=1} \\mathcal{H} _{ij}\\cdot d _{ij}$$ 其中第一项鼓励 $\\mathbb T$ 每行的和接近 $1$；第二项惩罚 $\\mathcal{H}$ 中的自环；第三项对应上面的第二个条件，即让图里所有边的加权和尽可能小。最理想的情况下前两项都是 $0$，$\\mathcal L$等于TSP最优解的路径长度。UTSP 通过设置这样的 loss 函数，让神经网络输出的结果靠近理想的 heatmap。\n此外，文章使用了 Scattering Attention GNN (SAG) 作为神经网络，在搜索前用 top-k 缩小搜索空间，并使用 Heat Map Guided Best-first Local Search 作为局部搜索方法。\n优势与局限性 根据文章，UTSP 的优势是：\n相比于有监督学习，UTSP 不需要有标注的数据，相比于强化学习，UTSP 的收敛速度更快（需要的样本数量更少）； UTSP 直接从 heatmap 计算 loss，省去了强化学习依赖采样获得 reward 的过程； 通过结构设计保证输出的 heatmap 含有汉密尔顿环路； 神经网络很轻量化（TSP100 仅需两层 45k 个参数）； 可以有效地减小搜索空间。 我认为 UTSP 的局限性是：\n根据提供的实验数据，UTSP 即使有轻量化的网络，它生成 heatmap 需要的时间依然比 Att-GCRN[2] 要长（为什么呢？）； Soft indicator 是针对 TSP 的巧妙设计，只适用于解为汉密尔顿环的问题，并且 UTSP 需要针对问题精心设计 loss 函数，因此将 UTSP 迁移到别的组合优化问题时，相比于一些有监督学习和强化学习方法（分别可以通过有标签的数据和 reward 学习问题特征）需要更多工作。 几个问题：\n在将边权重输入网络时，文章进行了预处理：$w_{ij}=e^{-d_{ij}/\\tau}$，这样做除了将输入映射到 $(0,1]$ 之外，相比于直接输入 $w_{ij}=d_{ij}$ 还有什么作用嘛； 如果不采用 Soft indicator，实验结果会有多大变化。 相关文献 [1] Y. Min, Y. Bai, and C. P. Gomes, “Unsupervised Learning for Solving the Travelling Salesman Problem,” in Advances in Neural Information Processing Systems, A. Oh, T. Neumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, Eds., Curran Associates, Inc., 2023, pp. 47264–47278. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2023/file/93b8618a9061f8a55825c13ecf28392b-Paper-Conference.pdf⤶ [2] Z.-H. Fu, K.-B. Qiu, and H. Zha, “Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 8, pp. 7474–7482, May 2021, doi: 10.1609/aaai.v35i8.16916.⤶ ","date":"2024-03-12T15:05:23+08:00","image":"https://files.furffisite.link/blogimg/20240312193735-df25ede3714c69d2ea8b42ba9c39f7c9-755f3.jpg","permalink":"https://blog.furffisite.link/p/read-papers/utsp/","title":"【读论文】Unsupervised Learning for Solving the Travelling Salesman Problem"},{"content":"之前的事情：\n我折腾NAS的历程（一） 我折腾NAS的历程（二） 我折腾NAS的历程（三） 本文以上一篇的自组 NAS 为基础，升级了一些配置，就性价比而言感觉这钱花得不算太值。\n硬件部分 品牌 型号 参数 购买价 CPU Intel E5-2690 v4 14 核 2.6GHz 规格表 ¥134（洋垃圾） 内存 Samsung M386A4G40DM0-CPB DDR4 2133 MHz 32GB 规格表 ¥155（洋垃圾） 接口扩展 （主控）Marvell 88SE9215 PCIe2.0x1 转 SATAx4 规格表 ¥75 总计 ¥364 CPU 同样是按照之前的设置，使用sysbench粗测的对比如下：\nCPU 主频 TDP Events/s Avg. Latency E5-2660 v4 2.0 GHz 105 W 17251.86 1.62 ms E5-2690 v4 2.6 GHz (+30%) 135 W (+28.6%) 22860.48 (+32.5%) 1.22 ms (-24.7%) 考虑到这两块 CPU 除了主频和功耗外几乎一致，性能成比例地提升确实是预料之中。也就是说我为了 30% 的性能提升多花了 157.7% 的钱，性价比不算高， 不过主频的提升对于一些多线程优化不好的任务（例如 Minecraft 服务器）还是有用的。\n此外我买到的似乎是这个商家的最后一块 E5-2690 v4，我下单后回到详情页就发现这个型号缺货了。\n内存 我本来认为这个 32GB 的内存条和之前购买的 16GB 内存条是兼容的，因为我在我的笔记本上用的就是 8GB+32GB 的非对称双通道的配置。 内存条到货之后才发现，虽然这两条单独安装都是能正常启动的（说明两条都没坏），但是两者同时安装的时候，无论放在哪两个插槽，NAS 都无法开机。 这让我感觉很奇怪，奈何也找不到解决方法，只好当作是主板/CPU 不支持，并闲置原来的 16GB 内存条。\nPCIE转SATA扩展卡 这个是在淘宝上随便找的一个。因为我需要接的也都是机械硬盘，传输瓶颈还是在机械硬盘的读写上，所以我对速率没什么要求，能跑满机械硬盘的读速就可以。\n至于它是不是真的值 75 元就不得而知了。\n扩展完 SATA 口之后，机箱内一共有 7 个 SATA 接口，但是只有4个硬盘位，我想下一步应该是购买硬盘支架了。\n软件部分 Gitea Gitea 是开源的代码托管平台。 自己有时候写了一些工具项目，不想向 Github 上传的时候（担心隐私问题，以及大陆地区访问 Github 有时连接不畅），就会传到自建的 Gitea 上。\n虽然名字和 Gitee 只差一个字母，但是它们应该没有任何关系。 类似的自建代码托管平台还有 GitLab 和 Gogs等。 不用 GitLab 是因为 GitLab 的资源占用太大了，并且我也基本用不到它的 CI/CD 功能。\nGitea 可以直接使用 docker 镜像部署，具体参照 Gitea 官方文档。\nImmich Immich 是开源自建的相册服务，类似于谷歌相册，提供了图片管理、人脸识别、地图和智能搜索等功能，并且在 IOS、Android 和网页端都有官方的客户端。\n这个项目各方面都挺不错的，缺点是版本更新有点太快了，最快的时候一周能发三四个版本。当然对于项目而言这是好事，是项目活跃的证明，但是对于使用体验而言就不那么好了。 它更新的时候可能会引入 breaking changes，这就要求每次更新前都要到其 github 的发布页查看升级前的注意事项，然后才能用 docker compose 拉镜像。 拉镜像的过程也有些折磨，因为镜像实在太大了。\n官方文档里给出了使用 docker compose 部署 Immich 的方法。\nLANraragi LANraragi 是用 Perl 语言编写的自建漫画库和漫画阅读器。 优势是通过浏览器访问，且支持直接从 zip、tar.gz 等压缩文件/归档文件读取图片，而不用手动解压。\n缺点是它对 unicode 的支持不太好，我觉得 Lanraragi 在管理漫画方面的功能也比较欠缺，不算特别好用。 可以先找找它的替代品，找不到的话不妨有空自己动手用 golang 实现一个。\n官方文档给出了使用docker部署的方法。\n主页（homer） NAS上运行的服务多了，每次访问服务都要输地址（无论是 ip + 端口还是内网域名）会很麻烦，于是用 homer 搭建了 NAS 的入口页。\n由于是纯静态的网页（改完配置也不需要重新编译之类的），部署的时候进项目的 release 页下载编译好的 zip 文件解压，然后直接在 nginx 里添一个 server 就行，也可以改 default，让它成为路由无匹配时的默认页面。配置时只要改assets/config.yml，在浏览器里刷新页面（可能需要在开发者工具的 networks 里 Disable Cache）就能看到更改了。\n百度网盘客户端 之前在复习备考的时候，有很多考研资料是通过百度网盘流传的。 又因为百度网盘的限速，和它的一些操作让我不是很想在本机安装它的客户端，催生了我在 NAS 上部署其客户端的需求。 一搜果然有大佬做好了百度网盘客户端的 docker 镜像，其中之一是 gshang2017 做的 。\n把指令转换成docker-compose.yaml文件，然后docker compose up -d，不出意外用浏览器访问 NAS 的 5800 端口就能看到登录界面了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 services: baidunetdisk: image: johngong/baidunetdisk:latest volumes: - ./config:/config - \u0026lt;path to downloads\u0026gt;:/config/baidunetdiskdownload container_name: baidunetdisk ports: - 5800:5800 # web - 5900:5900 # vnc restart: unless-stopped environment: - VNC_PASSWORD=12345678 - USER_ID=1000 - GROUP_ID=1000 - NOVNC_LANGUAGE=\u0026#34;zh_Hans\u0026#34; 因为这个镜像是以官方的 linux 客户端为基础制作的，功能基本上与之相同。除了广告点不开（这是好事）之外我在使用过程中没有遇到什么问题。\n饥荒服务器 我的舍友想要联机玩饥荒（Don\u0026rsquo;t Starve (Together)），于是拜托我在 NAS 上搭了一个饥荒服务器（不过我自己没什么兴趣就是啦）。\n我在 Docker 上没找到下载量较多的镜像，于是按照知乎和 Fandom wiki 的教程搭建了环境（配置起来还挺麻烦），然后写了dnst.service让它作为 systemd 服务运行和自启动：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [Unit] Description=DoNotStarveTogether Server After=network.target [Service] User=steam Group=steam Type=simple WorkingDirectory=/home/steam ExecStart=/home/steam/rundst.sh TimeoutStopSec=2min Restart=always [Install] WantedBy=multi-user.target 虚拟化（KVM） 关于虚拟机，我之前只用过图形界面的 VirtualBox，这是我第一次接触 Linux 服务器上常用的 Kernel-based Virtual Machine（KVM）。 我是按照这篇教程在服务器上安装的KVM，按照这篇教程在本机（Arch Linux）安装了Virtual Machine Manager。\n目前只是在虚拟机里装好了 Ubuntu 系统，还没有深入折腾。\n","date":"2024-03-09T23:53:36+08:00","image":"https://files.furffisite.link/blogimg/20240310022612-8671164f59f21e5d03de82e41e7073d5-7f2c7.jpg","permalink":"https://blog.furffisite.link/p/nas-4/","title":"我折腾 NAS 的历程（四）：一些升级"},{"content":"考研初试结束后，我在淘宝上给自己买了个 64GB 的 LCD 版 Steam Deck，当时（2023年12月底）花了￥2885.90.\n扩容硬盘与恢复系统 我是为了省钱才买的 64GB 版本，但是 64GB 的外存显然不够用，所以我又买了一块 2230 尺寸的 2TB NVMe 硬盘（西数 SN740），硬盘+散热片共花费 ￥744.90. 这样算下来购买 64GB 版本自己加硬盘比直接买商家改的 2TB 版本划算且更有保障。\n下面是更换硬盘及其后续操作的步骤。\n第一步：备份存档 如果是刚到手的新机，或者有硬盘盒支持拆下来的 64GB 的硬盘的话倒也不必要这一步。 如果拿到手之后已经玩了一段时间，游戏不支持 steam 云存档（或者各种原因导致没有同步成功），且手边没有硬盘盒的话，一定要在更换硬盘之前备份一下 Steam Deck 上的游戏存档。\n进入 SteamOS 的桌面模式后插入 U 盘，使用指令或图形界面复制文件夹 /home/deck/.local/share/Steam/steamapps/compatdata 到 U 盘内。\n第二步：更换硬盘 更换硬盘的操作可以直接参考 iFixit 的教程 [1]。\n第三步：恢复SteamOS 这部分的操作可以参考 Steam 官方的教程 [2]，我在此记录一下我踩到的坑：\nSteam 提供的镜像不能使用 Ventoy 启动，只能老老实实用工具（Rufus / balenaEtcher / dd）写到空 U 盘或 microSD 卡内； 我最开始用的是 U 盘，但是在 Steam Deck 上从 U 盘启动时在黑屏卡住了，后面在 reddit 用户的建议下 [3] 换用了 microSD 卡（三星 EVOPlus 64GB）才顺利进入桌面（不知是 hub 的问题还是 U 盘的问题，踩这个坑让我多花了两三个小时）。 恢复好系统后就可以弹出 U 盘或 microSD 卡，从硬盘启动了，之后系统初始化的步骤和刚拿到机器时的一样。\n第四步：硬盘分区 进入桌面模式，使用 KDE Partition Manager 按照需求调整分区，如果有双系统需求的要给 Windows 预留好安装空间（我留了 250GB），并且把两个系统共享的游戏文件分区格式化为 NTFS 文件系统。\n我的分区方案如下：\n其中，我给 SteamOS 的 home 分区分配了 200GB，用于存放只有 SteamOS 用得到的工具，另外 SteamOS 会默认把游戏存档、运行环境和游戏预编译的着色器放在这里，目前的使用情况如下：\n然后配置开机自动挂载，这算是 Linux 用户的基操吧，我就不赘述了，可以参考 [4] [5]。\n配置好之后重启（或者使用 sudo mount -a 挂载新分区），进入 Steam 在新分区上创建游戏库即可。\n安装双系统 首先要明确自己有没有在 Steam Deck 上安装双系统的需求，我要装 Windows 是因为：\n有些 Windows 游戏不支持 SteamOS； 对于非 Steam 平台的游戏，使其在 SteamOS 上正常运行需要耗费一定的精力。 第一步：安装 Windows AtlasOS 相当于非官方的精简版 Windows，我觉得在侧重于游戏的 Steam Deck 上安装这个非常合适，LinusTechTips 也出过一期视频介绍它 [6]。 至于视频评论里提到的安全性问题我倒不太担心，因为我在这上面无非就是运行 Steam 和一些游戏，我知道自己在做什么，要是真出了问题重装就行。\n安装 AtlasOS 的步骤参见 [7]。我激活 Windows 时用的是学校的 KMS 服务。\n注意：安装 Windows 时使用的 ISO 文件只能从这个页面生成的链接下载，否则 Windows 版本对不上，到后面使用 AME Wizard 的时候会报错。 我踩中了这个坑，浪费了一个小时。\n第二步：安装驱动 Steam Deck 上刚装好的 Windows 系统时没有音频输出的，原因是缺少相关驱动。 此时要按照 Steam 的指南 [8] 下载并安装里面提供的所有驱动。\n可是装完驱动后我发现屏幕亮度的调节还是存在一些问题：Windows 里调整亮度的范围比 SteamOS 的小好多，不过这不太影响日常使用，所以我就没管了。\n第三步：双系统的常见问题 目前遇到两个，这是安装双系统的计算机都会遇到的问题，并非 Steam Deck 独有的：\n双系统时间不一致，解决方法可以参考 [9]； 双系统无法共享蓝牙设备，解决方法参考 [10]； 在 Linux 内无法访问双系统共享磁盘，解决方法是关闭 Windows 的快速启动，参见 [11]。 第四步：安装辅助工具 Steam Deck Tools [12] 提供了改善在 Steam Deck 上使用 Windows 体验的一系列工具，包括手柄模拟，性能监视器，TDP控制等。 其中手柄模拟（Steam Controller）我觉得是必要的。\n相关问题 SteamOS更新后引导消失 近日我更新了 SteamOS 版本，更新后 SteamOS 从启动项菜单消失了，最终按照 [13] 提供的修复方法成功恢复启动项。\n相关资料 参考资料 [1] Steam Deck SSD 更换 - iFixit 维修指南⤶ [2] Steam Support :: Steam Deck Recovery Instructions⤶ [3] Recovery image not booting : r/SteamDeck⤶ [4] fstab - Arch Linux 中文维基⤶ [5] 开机自动挂载硬盘 — Linux latest 文档⤶ [6] 【官方双语】你不需要新电脑(赞助)#linus谈科技_哔哩哔哩_bilibili⤶ [7] Installation - Atlas Documentation⤶ [8] Steam Support :: Steam Deck - Windows Resources⤶ [9] Linux Windows 双系统时间不一致 - 少数派⤶ [10] Linux 与 Windows 双系统共享蓝牙鼠标 - 南浦月⤶ [11] 终极指南：如何在 Windows 10/11 中关闭快速启动 - HowToHi⤶ [12] README | (Windows) Steam Deck Tools⤶ [13] Steamdeck双系统系统引导通用修复指南——以SteamOS更新掉引导为例 - 哔哩哔哩⤶ 其它资料 Steam Deck™ 非常适合 Deck 【爱折腾】SteamDeck完全折腾指南_哔哩哔哩_bilibili Steam Deck单硬盘双系统+互通游戏库详细教程 - 哔哩哔哩 Steam deck双系统疑难杂症记录帖 - 哔哩哔哩 Steam Deck上手折腾指南 换硬盘 双系统 内存卡互通新手教程_哔哩哔哩_bilibili SteamDeck双系统启动项一键替换为Refind - 哔哩哔哩 SteamDeck Windows 和 Steamos 共享游戏库教程 - 哔哩哔哩 ","date":"2024-02-19T20:12:35+08:00","image":"https://files.furffisite.link/blogimg/20240220134919-e7ed5ace1e94b03d7e56a619a0f7a6d7-5ca68.jpg","permalink":"https://blog.furffisite.link/p/steamdeck-tweaking/","title":"Steam Deck 折腾记录"},{"content":"我因为之前做实验时习惯不好（一边训练一边改代码），没有保留好实验记录惹出了一些麻烦（不知道发布的模型具体是怎么训练出来的），觉得有必要确立几条原则防止以后再出现类似的情况。 为了确保每次实验都是完全可复现的，以下是我的想法：\n使用 git 管理实验代码版本，在程序内强制要求长时间训练模型前 commit 所有修改，并且在 commit 记录内写清楚每次做出的更改； 使用logging模块替代print，以将带时间戳的记录同时输出到控制台和 log 文件； 在程序运行前输出所有超参数与运行时间； 在训练时使用运行时间与 commit id 的前几位创建文件夹，并将此次训练产生的所有文件都组织到这个文件夹内，测试记录可以和模型放在一起。 固定并输出 random seed； 使用服务器训练时应及时下载训练记录。 实现 原本想自己实现的，这个时候发现了 meta 开源的 Hydra 库，似乎它提供的功能能实现其中几个想法。\n","date":"2023-12-26T18:07:49+08:00","image":"https://files.furffisite.link/blogimg/20240101025358-39157c666fdfaedad07996f1f3e91a67-39937.jpg","permalink":"https://blog.furffisite.link/p/experiment-record-management/","title":"关于实验记录的管理"},{"content":"本文旨在回顾我这三个月准备考研的经历。无论结果如何，我想给自己留下一份奋斗的记录，如果能帮到后来者那就更好了。\n背景 在五月份的时候，我知道我处在保研排名的边缘，有一定可能获取不到推免资格，于是我在当时购买了几本参考书，并且复习了一小段时间的高等数学。 但是随着夏令营、预推免和毕业实习等工作的推进，我动摇了，一度认为自己真的能成功保研，完全将复习考研抛之脑后。 等到我反应过来的时候，已经是 2023 年 9 月 18 日，学院公布推免指标分配方案的时候，其中我的专业的推免指标仅为同学院其余两个专业的二分之一与三分之一（总人数相近），远低于我的预期。 以公布的名额数量来算，推免名额轮不到我，这时我才清醒——保研这条路我肯定是走不通了。\n考研是12月23日，当时已经是9月18日，也就是说留给我的复习时间仅有三个月，如何合理安排复习时间，最大化我的考研分数，便是我当时需要解决的问题。\n调查阶段 调整心态 无法保研的信息让当时的我陷入了绝望，感觉已经无路可走了——因为在当时的我看来考研真的好难，而我又没有进入工作的心理准备（更何况还是在互联网寒冬的当下），出国对家里造成的经济负担又太大了。 我当时一度有过轻生的念头，好在我没有任何实施它的勇气，这时调整好心态，重新振作起来是最重要的。 在家人和朋友们的帮助下，我逐渐看开了，意识到考研可能没有想象中的那样艰难，于是确立了考研的目标。\n确定目标 在努力复习的同时，选择一个好的目标院校同样重要，因为 10 月初就要报名了。 别的考研同学可以通过之前几个月的复习时间找准自己的定位，从而决定好一个匹配自己水平的学校。 相较于他们，我只能在两周的时间内确定一个我通过仅仅三个月的复习时间有较大把握考上的学校和专业。\n首先排除本校，经过保研这事我已经不想在本校待着了（更何况学校挺热门的……不好考）。 在用爬虫抓取了研招网的专业目录并在本地筛选后，我筛选出了几个目标，包括北京邮电大学、东南大学（简称东大）等。 考虑到我的复习时间和之前预推免的情况，在与家人沟通、参考了网络上一些在读或毕业学长学姐的经验帖后，我最终选择了相对比较好考的东南大学-蒙纳士大学苏州联合研究生院（简称东蒙）。\n好考是有原因的——因为是中外合办的学院，学费相较于别的学校和学院贵很多[1]，所以竞争对手相对较少，往年的分数线低[2]，报考-录取比也较低[3]。\n分析现状 东蒙电子信息专硕的考试科目是 101 思想政治理论、201 英语（一）、301 数学（一）和 935 计算机专业基础（东南大学自命题）。 935的考纲会在东大计算机学院官网发布[4]，包括操作系统、计算机组成原理、数据结构，其中操作系统占比最大。\n知道了要考什么，接下来就要分析现状了，依此分配复习时间。\n我当时的状况是：高数只看完极限和一元函数的微分学，其余学科完全没复习。 我的优势是英语不错：六级分数 605，英语一真题的选择题大多能在一个小时内做完，且扣分在 8 分以内，所以几乎不用太多时间复习英语。 935 要考的三门我掌握的也不错，只需要回顾一下知识点，做一些题即可。 我的劣势是我背书很难背下来，因此以背书为主的政治于我而言较为困难。\n复习 我的基础复习阶段大概是 9 月 20 日- 11 月中旬，大约两个月时间。因为复习的时间有限，各科的复习是同时进行的。 强化和冲刺阶段是 11 月中旬一直到考试前。\n数学（一） 数学一分为三个子科目：高等数学、线性代数、概率论与数理统计，占比最大的是高等数学，因此在复习数学时要着重准备高等数学。\n在同学的推荐下，我高数部分跟的是张宇的课，张宇的优点是在基础阶段讲的很全面，也会顺带着讲一些技巧，适合我这种时间紧张的人；线性代数部分最开始跟的是李永乐，但是没听下去，后来就转汤家凤了；概率论部分没有看课，只是看书回忆自己大一学的东西。在看课的同时，做题巩固也很重要，我的节奏是看完一章的课就把《张宇 1000 题》对应的章节的 A、B、C 部分做完，C 部分的题做不出来的暂时也不用深究。\n在强化阶段主要写之前不会写的C 组题，C 组题做完了就做真题，同时看重点/常考知识点的强化课程（来不及全看完了），例如高等数学的中值定理、无穷级数、线性代数的二次型等。\n冲刺阶段接着做真题，以及张宇的 8 套预测卷和 4 套终极预测卷。\n参考书目：张宇基础 30 讲、张宇 1000 题、数学一真题、张宇 8 套预测卷、张宇 4 套终极预测卷 英语（一） 如上文所述，我只要做真题的选择题就可以了，平时可以带着用 app 背考研词汇。 冲刺阶段再补一补小作文的格式和大作文的写法。\n参考书目：英语一真题集 计算机专业基础（自命题） 935 是东南大学的自命题科目，包括操作系统、计算机组成原理、数据结构三个部分。 准备自命题科目的难点是资料很少，并且相比于统考科目，老师出题也比较随心。 根据往年上岸的学长学姐的经验帖，复习 935 可以看 408 的相关资料，课也可以直接跟王道的 408 课程。 因此我复习用的资料主要是王道考研的系列书籍。\n东南大学给出了下面四本书作为参考书目：\n《操作系统概念(第7版)》(翻译版) 西尔伯查茨(Abraham Silberschatz)、郑扣根等，高等教育出版社 2010-01 《数据结构(C语言版)》 作者：严蔚敏、吴伟民 出版社：清华大学 时间：2011-07-01 《数据结构(用面向对象方法与C++语言描述，第2版)》作者：殷人昆 出版社：清华大学 时间：2014-9-23 《计算机组成原理（第2版）》，任国林，ISBN 978-7-121-33462-7，2018.1 前三本我觉得用处不大，而计算机组成原理这部分据说是由任国林老师亲自命题，所以他写的教材是很有必要看的。\n到了强化和冲刺阶段我做了 408 的真题，至于 935 的真题我没找到资源就没做。\n参考书目：王道考研系列 操作系统/数据结构、计算机组成原理（任国林 著）、408 真题、935 真题（如果能找到的话） 视频课： 王道计算机考研 计算机组成原理 、 王道计算机考研 操作系统 、 王道计算机考研 数据结构 思想政治理论 政治这门课我跟的是徐涛的课，在基础阶段一边看课一边刷选择题。\n到了冲刺阶段，等肖八出来就写肖八的选择题，肖四出来后狂背客观题，今年肖秀荣老师几乎全押中了（考前还不信，没想到肖老师真的这么厉害）。\n参考书目：考研政治核心考案（徐涛）、肖 1000、肖八、肖四 相关资料 [1] 东大研招网 - 东南大学—蒙纳士大学苏州联合研究生院2024年硕士研究生招生简章⤶ [2] 东大研招网 - 2023年东南大学各院系所复试分数线⤶ [3] 东大研招网 - 2023年硕士研究生考试录取情况汇总⤶ [4] 东南大学计算机科学与工程学院 - 2024年计算机科学与工程学院硕士研究生入学考试930、935考试大纲⤶ ","date":"2023-12-25T11:02:45+08:00","image":"https://files.furffisite.link/blogimg/20231226003721-76bafcf83bb54ee4b8d8524cc179b790-e34bc.jpg","permalink":"https://blog.furffisite.link/p/kaoyan-stage1/","title":"考研经历 - 准备初试"},{"content":"深度Q学习算法 理论 深度Q学习算法（Deep Q-Learning Algorithm）是将 Q 表格替换为神经网络的 Q 学习算法，由 DeepMind 的 Mnih et al. [1][2]提出。 Q表格本质上是一个函数 $f: S\\times A \\rightarrow \\mathbb{R}$，我们自然也可以使用神经网络构造这个函数，让它可以处理连续的状态和动作。此外，使用神经网络还有一个好处：我们可以向神经网络输入实例信息 $m\\in M$ ，使之可以跨实例学习函数 $f: M\\times S\\times A\\rightarrow \\mathbb{R}$ 。也就是说，Agent可以将其在实例 $m_1,m_2,\\ldots~m_n$上 学习到的经验迁移到未曾见过的实例 $m_{n+1}$ 上，增强模型的泛化性能，减少其探索新实例所需的时间。\n网络更新方程的设计 （以 Bellman 方程 为基础）： $$Q(s_t, a_t) \\leftarrow (1-\\eta) Q(s_t, a_t) + \\eta(\\gamma\\max_{j\\in A} Q(s_{t+1}, j) + r_t)$$\n求更新前与更新后的差分： $$\\Delta Q(s_t, a_t) = -\\eta Q(s_t, a_t) + \\eta(\\gamma\\max_{j\\in A} Q(s_{t+1},j) + r_t)$$\n即： $$\\Delta Q(s_t, a_t) = \\eta(\\gamma\\max_{j\\in A} Q(s_{t+1},j) + r_t - Q(s_t, a_t))$$\n在理想情况下充分训练时，应当有 $$\\lim_{t\\rightarrow \\infty}\\Delta Q(s_t, a_t) = 0$$\n也就是说，训练的目标应当是最小化 $\\Delta Q(s_t, a_t)$，即目标函数为： $$L(\\theta) = \\mathrm{MSE}(Q(s_t, a_t),~\\gamma\\max_{j\\in A} Q(s_{t+1},j) + r_t)$$ 其中的 $\\mathrm{MSE}$ 也可以替换为其它的损失函数。\n实现 下面以CartPole-v1环境为例编写训练程序。\n引入相关的库以及定义一些超参数：\n1 2 3 4 5 6 7 8 9 10 11 12 from random import random, randint import gymnasium as gym import torch import torch.nn as nn from tqdm import tqdm n_actions = 2 n_states = 4 lr = 3e-4 discount = 0.95 batch_size = 128 epochs = 5000 定义神经网络，这里定义了一个简单的三层神经网络，其中输出层没有添加激活函数是因为激活函数会限制网络的值域至 $R_{act}$ ，设Q函数的值域是 $R_Q$，$R_Q\\nsubseteq R_{act}$ 时损失函数难以收敛，影响训练效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class Net(nn.Sequential): norm_vector = torch.tensor([0.5, 1.0, 0.21, 0.5]) def __init__(self, in_feats = n_states, out_feats = n_actions, hidden = 32): super().__init__( nn.Linear(in_feats, hidden), nn.SiLU(), nn.Linear(hidden, hidden), nn.SiLU(), nn.Linear(hidden, out_feats), ) def forward(self, state): x = state/self.norm_vector # 归一化 y = super().forward(x) return y 定义网络、优化器与损失函数：\n1 2 3 net = Net() optimizer = torch.optim.AdamW(net.parameters(), lr=lr, amsgrad=True) criterion = nn.SmoothL1Loss() # 发现L1的效果比L2要好 训练过程（原环境提供的 reward 恒为 1，信息太少，因此这里改用自定义的 reward，在倾角过大或位置过远时进行惩罚）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 env = gym.make(\u0026#34;CartPole-v1\u0026#34;) state, info = env.reset() for t in tqdm(range(epochs)): # 前向传播 loss = 0.0 epsilon = 1 - t / epochs # 动态调整epsilon for _ in range(batch_size): # 选择action ========================= row = net(state) if random() \u0026lt; epsilon: # exploration action = randint(0, n_actions-1) else: action = row.squeeze().argmax().item() # 执行action ========================= state, reward, terminated, truncated, info = env.step(action) # 使用自定义的reward reward = -20.0 if terminated else 0 if abs(state[2]) \u0026gt; 0.1: # 限制倾角 reward += -1.0 if abs(state[0]) \u0026gt; 0.3: # 限制位置 reward += -2.0 if reward \u0026gt;= 0: reward = 1.0 # 计算loss ========================= with torch.no_grad(): if terminated: curr_q = torch.tensor(reward) else: curr_q = net(state).max() * discount + reward loss += criterion(row[action], curr_q) if terminated or truncated: state, info = env.reset() # 反向传播 optimizer.zero_grad() (loss/batch_size).backward() torch.nn.utils.clip_grad_value_(net.parameters(), 1) optimizer.step() env.close() # 保存checkpoint torch.save(net.state_dict(), \u0026#34;cartpole.ckpt\u0026#34;) 推理：\n1 2 3 4 5 6 7 8 9 10 11 env = gym.make(\u0026#34;CartPole-v1\u0026#34;, render_mode=\u0026#34;human\u0026#34;) state, info = env.reset() with torch.no_grad(): for t in range(2000): row = net(state) action = row.squeeze().argmax(0).item() print(row) state, reward, terminated, truncated, info = env.step(action) if terminated or truncated: state, info = env.reset() env.close() 不出意外的话，运行程序后可以看到类似于这样的动画，说明这个算法以及我们编写的程序都是有效的： 完整的程序见Github Gist，模型权重可以从这里下载（虽然自己训练一个也不费事）。\n经验回放 理论 上面的训练 Q 网络的方式存在一些问题，例如\n样本的利用率低：每次采样只对应一次前向传播，采样得到的样本未被充分利用； 样本的时序关联性大：每次采样在时间上是高度相关的，上一次采样的末状态就是下一次采样的初始状态，影响训练效果； 训练速度慢：每次前向传播只传播一组数据，速度较慢。 为了缓解上述问题，Mnih et al.[2] 在提出深度 Q 学习的同时也提出了经验回放（Experience Replay）策略。 其主要思想是将采样与训练分离，采样时在记忆中保存采样的记录，训练时随机从记忆中选取样本进行前向与反向传播，从而降低样本间的时序关联性与提高样本利用率。\n注意到在算法中，每一步训练需要四个值：当前状态 $s_t$、动作 $a_t$、回报 $r_t$ 以及采取动作后的状态 $s_{t+1}$，因此每一次采样后只需要在记忆中保存这四个值，称为 experience 四元组 $e_t=(s_t,~a_t,~r_t,~s_{t+1})$。\n实现 库、超参数、网络结构以及推理部分均沿用上面的代码以便比较，只替换训练部分，然后新增 Experience 类与 Memory 类用于存储和管理样本。 以下是 Experience 类与 Memory 类的代码，这里使用队列存储最新的 batch_size*10 条记录：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 from typing import NamedTuple, Union class Experience(NamedTuple): \u0026#39;\u0026#39;\u0026#39;experience四元组\u0026#39;\u0026#39;\u0026#39; state: np.ndarray action: int reward: float next_state: np.ndarray class Memory(object): \u0026#39;\u0026#39;\u0026#39;存储固定数量记录的队列\u0026#39;\u0026#39;\u0026#39; def __init__(self, buffer_size: int): self.buffer_size = buffer_size self.buffer: list[Union[Experience, None]] = [None for _ in range(self.buffer_size)] self.count = 0 def append(self, exp: Experience): \u0026#39;\u0026#39;\u0026#39;增加记录，如果buffer已满则替换最早的记录\u0026#39;\u0026#39;\u0026#39; self.buffer[self.count%self.buffer_size] = exp self.count += 1 def sample(self, k: int): \u0026#39;\u0026#39;\u0026#39;随机选取k个experience，打包好返回\u0026#39;\u0026#39;\u0026#39; if self.count \u0026lt; self.buffer_size: pool = self.buffer[:self.count] else: pool = self.buffer exp: list[Experience] = random.choices(pool, k=k) # type: ignore # 打包成 Tensor states = torch.from_numpy(np.array([e.state for e in exp])) actions = torch.tensor([e.action for e in exp]) rewards = torch.tensor([e.reward for e in exp]) next_states = torch.from_numpy(np.array([e.next_state for e in exp])) return states, actions, rewards, next_states memory = Memory(batch_size*10) 采样的部分与原来相同，而在训练的部分，因为这里训练时前向和反向传播都只有一步，所以在计算target_q时不需要像原文所述冻结权重，只要在其后增加.detach()确保反向传播时target_q的梯度不被传播就行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 env = gym.make(\u0026#34;CartPole-v1\u0026#34;) state, info = env.reset() batch_index = torch.arange(batch_size) for t in tqdm(range(epochs)): # 采样 ========================================= epsilon = 1 - t / epochs # 动态调整epsilon for _ in range(batch_size//4 if t \u0026gt;= 1 else batch_size): if random.random() \u0026lt; epsilon: # exploration action = random.randint(0, n_actions-1) else: action = net(state).squeeze().argmax().item() org_state = state state, reward, terminated, truncated, info = env.step(action) # 使用自定义的reward reward = -20.0 if terminated else 0 if abs(state[2]) \u0026gt; 0.1: # 限制倾角 reward += -1.0 if abs(state[0]) \u0026gt; 0.3: # 限制位置 reward += -2.0 if reward \u0026gt;= 0: reward = 1.0 # 加入记忆 memory.append(Experience(org_state, action, reward, state)) if terminated or truncated: state, info = env.reset() # 训练 ========================================= states, actions, rewards, next_states = memory.sample(batch_size) # 前向传播 pred_q = net(states)[batch_index, actions] target_q = (net(next_states).max(dim=-1).values * discount + rewards).detach() loss = criterion(pred_q, target_q) # 反向传播 optimizer.zero_grad() loss.backward() torch.nn.utils.clip_grad_value_(net.parameters(), 1) optimizer.step() env.close() # 保存checkpoint torch.save(net.state_dict(), \u0026#34;cartpole-replay.ckpt\u0026#34;) 完整程序见 Github Gist，运行程序，发现两个程序在batch_size=128和epochs=5000的情况下，原来的程序在我的轻薄本上需要训练 3 分钟，而得益于批处理的训练过程以及采样数的减少，有经验回放的训练只要 15 秒就能达到更好的效果。\n继续增加batch_size或epochs，效果更佳。以下是batch_size=256、epochs=5000的结果，训练只花了 28 秒。\n参考文献 [1] Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., \u0026amp; Riedmiller, M. (2013). Playing Atari with Deep Reinforcement Learning (arXiv:1312.5602). arXiv. https://doi.org/10.48550/arXiv.1312.5602⤶ [2] Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidjeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., \u0026amp; Hassabis, D. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), Article 7540. https://doi.org/10.1038/nature14236⤶⤶ ","date":"2023-08-22T10:51:10+08:00","image":"https://files.furffisite.link/blogimg/20230822110113-5ef18ab6cfb63d5a730bbd8e077231e7-6ba69.jpg","permalink":"https://blog.furffisite.link/p/deep-q-learning/","title":"【RL学习笔记】深度Q学习算法与经验回放"},{"content":"我开始折腾NAS的原因很简单——笔记本的存储空间不够了，当时固态硬盘的价格远没有现在这么便宜，移动硬盘随身携带有点麻烦，所以就想给硬盘连上网，这样只要有网就能访问。\n当时是2021年3月，我手边有闲置的树莓派 3B+（19 年花 ￥279 买的），于是一个很朴素的想法就形成了——买一个 SATA-USB 的硬盘盒连接机械硬盘，再给树莓派连上网线，做成一个简陋的 NAS（后来才知道有 NAS 这个名字）。我后来也的确是这么操作的，硬盘盒买的绿联的，花了￥99。使用后发现树莓派 3B+ 的 USB2.0 接口太慢了，于是半年后（2021.9）买了带 USB3 的树莓派4B，花了￥578（当时这个价格已经很贵了，想不通为什么自己那个时候决定要买），所以这一套不算硬盘的价格是￥677。\n我使用的操作系统是树莓派官方提供的 Raspbian，在上面安装了\nsamba（文件服务）、 自己写的录播姬、 aria2（BT 下载）、 Coredns（因为学校的DNS服务器挂过一次）。 我认为树莓派作为 NAS 主要的优点是：\n结构简单，插电就能用，且易于携带； 耗电量很低； 自带 GPIO 接口，可以外接一些 LED 或 LCD 1602 显示服务器状态等，或是增加传感器以收集数据，这对于“折腾类”玩家又是一个可折腾的点。 缺点是：\n第一，它的 CPU 是 32 位 arm 架构的，这导致许多没有提供 32 位 arm 版本的程序它都无法运行，例如 qbittorrent、数据库、jellyfin 等，而受限于其性能，从源代码编译这条路也不简单（当然也可以使用 docker buildx 跨平台编译，但是当时的我还不会搞这些）； 第二，性能太弱； 第三，性价比不高。 相较于其优点，它的缺点还是太突出了，于是我在一年后（2022.10）换了amd64架构的NAS。\n","date":"2023-08-21T14:46:05+08:00","image":"https://files.furffisite.link/blogimg/20230821143533-8f90300e7a87f5103e8c13359c0ce9a7-a82cd.jpg","permalink":"https://blog.furffisite.link/p/nas-1/","title":"我折腾 NAS 的历程（一）：树莓派"},{"content":"时值 2022 年国庆节，我在淘宝翻了很久，找 x86/amd64 的 NAS 方案，最终相中了淘宝某家店卖的“青春版黑群晖”，CPU+主板+风扇+4GB 内存+亚克力外壳一共只要 ￥285，外带黑群晖的引导盘。这个价格很吸引我，于是我没过多考虑就下单了。\n货到之后发现这个主板似乎是工控机里拆出来的，CPU 是 12 年 Q1 出的 Atom D2550。主板上只有一个 SATA 口，其余的被拆掉了，于是商家增加了一个 SATA 转 M.2 接口的板子插在（疑似）M.2 口上，这样就能支持双硬盘了。因为我想让硬盘完全用来存储数据，所以我又花 ￥56.9 买了一个 64GB 的小 U 盘用来存储操作系统。\n操作系统选的是 Ubuntu Server 16.04，理由是相较于商家提供的黑群晖，我更熟悉 Ubuntu。软件和服务方面安装了 samba、jellyfin、qbittorrent、coredns 等。\n这个价格我很是满意，但是这台 NAS 的性能不比树莓派高多少，毕竟是十年前的处理器，导致它在一些高负载的情况下（例如 Jellyfin 使用 ffmpeg 转码播放视频）有些力不从心，播放时异常卡顿，所以在今年六月的时候趁购物节自己组了一台。换了新的之后发现，性能上去了，能同时跑的服务就多了很多，可以真的把它当作一台服务器来用了。\n","date":"2023-08-20T10:22:44+08:00","image":"https://files.furffisite.link/blogimg/20230821152623-0e0e9fdf80c6f1c9ffeee0f80f808e1e-60da9.jpg","permalink":"https://blog.furffisite.link/p/nas-2/","title":"我折腾 NAS 的历程（二）：淘宝工控机"},{"content":"组这台 NAS 前的事情：\n我折腾NAS的历程（一） 我折腾NAS的历程（二） 理论 装机配置单 品牌 型号 参数 购买价 购买链接 CPU Intel E5-2660 v4 14 核 2.0GHz 规格表 ¥52（洋垃圾） link 内存 Samsung M393A2G40DB0-CPB DDR4 2133MHz 16GB 规格表 ¥92（洋垃圾） link 主板 华南金牌 X99-4MF ITX DDR4x4 SATAx3 规格表 ¥268 link 系统盘 SKHynix HFS512GDE9X084N 512GB NVME ¥0* 显卡 NVIDIA GeForce 605 规格表 ¥16（亮机卡） link 电源 航嘉 GX500 500W ATX 白牌 ¥191.92 link 机箱 invasion invasion X1 4盘位 ITX ¥244 link CPU 散热器 零下30度 - - ¥38.7 link 机箱风扇 航嘉 MVP120 1500 RPM，支持 PWM ¥75.95（三只装） link 总计 ¥978.57 *笔记本上拆下来的\n攒机理念 目标：省钱、性能还行、体积小、静音、保留一定的可升级性、尽量一手。\n关于 CPU，我在CPUbenchmark上按照跑分结果在E5的一系列洋垃圾型号中从高到低翻，最后看中了 E5-2660 v4。选择它有以下几点理由：\n其功耗相比与同系列其它型号较低； E5-2660 v4 为 2016 Q4 推出的，相对 v3 和 v2 要新一点； 其性价比在同型号中较高，52 元 16005 分，相较于2690 v3 的 68 元 16505 分更实惠。 CPU 定下来了之后，主板和内存也就相应的决定了。之所以主板不选二手是因为我想省点事，对于二手市场上可能遇到的众多问题我目前没有任何应对经验。而选择 ITX 是为了满足体积小的要求，毕竟宿舍里放不下太多东西。\n关于系统盘，之前给笔记本升级外存的时候拆下来的原装 SSD 可以直接给它用。就算是买一个全新的也不会太贵，256GB 买个二线厂的 SSD 应该也够用了。 在装系统、进 BIOS 时显卡是必要的，作为服务器 CPU 的 E5-2660 v4 没有核心显卡，因此这里依然需要一张显卡。上淘宝一搜果然有卖亮机卡的，16 元的价格也就不用纠结值不值了，能亮就行。为了能看到视频输出我还买了一个二十多的 HDMI 采集卡以代替显示器，事实证明二十块的画质果然不行。 电源不敢买二手的，怕出问题。500W 的电源相对于目前的整机功耗明显是过剩的，但这也为以后的升级保留了余量。 最后是机箱，综合以上要求，机箱应该是体积小、轻便、便宜的多盘位 ITX 机箱，在淘宝上翻了一大圈只看到这一款同时满足这几点的。别的型号，例如蜗牛星际、御夫座、天箭座等都太贵了或者散热容量太小。两百多的机箱我觉得还是贵了点，可是也没找到更好的选择。\n关于可升级性，这套配置中，CPU 可以升级为 24686 分的 E5-2699 v4（在价格降下来之后），还有三个位置可以加内存条，显卡可以升级，机箱和电源以后也能用于装游戏电脑。\n实践 装机过程 装机过程中遇到的问题有四：\nCPU 散热器的螺丝是弯的（可能是制造问题），要用钳子扳直了才能安装； 机箱自带的硬盘笼和主板电源插槽有 2mm 左右的 overlap，装完之后硬盘笼有一点点变形。得益于硬盘架的减震机构，这个变形产生的影响不大； 主板下部的插槽和机箱风扇有冲突，前面板 USB-3 的线插不进去，但对于 NAS 而言这根线不插问题也不大； 华南金牌的这款主板的主板风扇插槽只有 3 针，不支持 PWM，直接插 MVP120 的话满转速噪音非常大。我最后用一拖三的线把所有风扇都接到了支持 PWM 的 CPU 风扇插槽上，这样就安静了很多（之后又进BIOS 调整了一下温度-转速曲线）。 操作系统 因为我最熟悉的 Linux 发行版是 Ubuntu，所以我安装了 Ubuntu 22.04.2 LTS（服务器版）。\n系统盘分区如下：\n1 2 3 4 5 6 Mountpoint Start End Sectors Size Type /boot/efi 2048 2203647 2201600 1G EFI System / 2203648 107061247 104857600 50G Linux filesystem /home 107061248 211918847 104857600 50G Linux filesystem /srv 211918848 958271487 746352640 355.9G Linux filesystem swap 958271488 1000214527 41943040 20G Linux swap 测试 整机待机时 CPU 核心平均温度为 30°C，满载时为 55°C，说明散热还是有很大的余量的。服务正常运行时插座上测量到的功率在 68W 左右，CPU满载时约 140W。\n使用 sysbench 的测试结果如下，和我现役的游戏本相比我觉得这个成绩还算可以接受：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3) Running the test with following options: Number of threads: 28 Initializing random number generator from current time Prime numbers limit: 10000 Initializing worker threads... Threads started! CPU speed: events per second: 17251.86 General statistics: total time: 600.0017s total number of events: 10351174 Latency (ms): min: 1.22 avg: 1.62 max: 82.58 95th percentile: 1.64 sum: 16797418.36 Threads fairness: events (avg/stddev): 369684.7857/436.76 execution time (avg/stddev): 599.9078/0.00 软件部分 Docker 最先安装的是 Docker，因为有了 Docker 之后别的应用都可以使用 Docker 镜像安装和管理。\n在 Ubuntu 上安装Docker只需使用官方提供的安装脚本[1]：\n1 2 $ curl -fsSL https://get.docker.com -o get-docker.sh $ sudo sh get-docker.sh 修改Docker数据位置 Docker 的数据默认储存在 /var/lib/docker 内，我想将其移到 /srv 文件系统内，操作如下：\n关闭docker服务：systemctl stop docker 移动文件：sudo mv /var/lib/docker /srv/ 创建符号链接（以防万一）：sudo ln -s /srv/docker /var/lib/docker 修改配置文件，在/etc/docker/daemon.json内添加配置：{\u0026quot;data-root\u0026quot;: \u0026quot;/srv/docker\u0026quot;} 启动docker服务：systemctl start docker 使用Docker国内镜像源 阿里云提供了免费的Docker镜像源的加速服务。为了使用该服务，需要在 https://aliyun.com 登录阿里云帐号，然后在 控制台 \u0026gt; 容器镜像服务 \u0026gt; 镜像工具 \u0026gt; 镜像加速器 处可以获取加速器的地址及修改镜像源的方法。\n此外也有一些开放的镜像源，在/etc/docker/daemon.json内添加如下属性 [2]：\n1 2 3 4 5 6 7 8 { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://hub-mirror.c.163.com\u0026#34;, \u0026#34;https://ustc-edu-cn.mirror.aliyuncs.com\u0026#34;, \u0026#34;https://ghcr.io\u0026#34;, \u0026#34;https://mirror.baidubce.com\u0026#34; ] } 修改后使用 systemctl restart docker 重启docker服务即可。\n手动下载镜像 如果替换了镜像源之后也拉不动镜像的话，可以试试 Moby Project 提供的镜像下载脚本下载镜像：link\n使用例：\n1 2 3 4 5 6 7 8 9 $ wget https://raw.githubusercontent.com/moby/moby/master/contrib/download-frozen-image-v2.sh $ bash ./download-frozen-image-v2.sh ./alpine-linux alpine:latest Downloading \u0026#39;library/alpine:latest@latest\u0026#39; (1 layers)... -#O=-# # # ############################################## 100.0% Download of images into \u0026#39;./alpine-linux\u0026#39; complete. Use something like the following to load the result into a Docker daemon: tar -cC \u0026#39;./alpine-linux\u0026#39; . | docker load 这时镜像就已经保存到./alpine-linux内了，然后使用\n1 2 3 $ tar -cC \u0026#39;./alpine-linux\u0026#39; . | docker load ...... Loaded image: alpine:latest 即可让 docker 导入镜像。\nsamba 1 $ sudo apt install samba 安装后使用smbpasswd -a \u0026lt;username\u0026gt;为用户添加 samba 的访问密码，其中\u0026lt;username\u0026gt;必须为已经在 Linux 内注册的用户。\n配置文件为/etc/samba/smb.conf，配置项可参考官方文档。\n1 2 3 4 5 6 [\u0026lt;share name\u0026gt;] path = /path/to/folder read only = no browsable = yes guest ok = no valid users = \u0026lt;users\u0026gt; jellyfin jellyfin 是数字媒体管理与串流软件，它支持浏览器、Android、iOS、Android TV 等许多客户端，可以在这些客户端上便捷地观看服务端存储的内容，这也是我攒这台 NAS 的主要目的。E5-2660 v4 的性能足以支持 jellyfin 流畅编解码超高清资源（软解，不过目前看来也没有专门为这个买 GPU 的必要了）。\n可以使用官方的 docker 镜像或者linuxserver.io 制作的镜像来安装 jellyfin。\n为了便于我管理和配置，所有的 Docker 容器都将使用 docker compose 启动。这是 jellyfin 的docker-compose.yaml：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 version: \u0026#34;2.1\u0026#34; services: jellyfin: image: lscr.io/linuxserver/jellyfin:latest container_name: jellyfin environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai volumes: - ./config:/config - /path/to/media:/data ports: - 8096:8096 - 8920:8920 #optional - 7359:7359/udp #optional - 1900:1900/udp #optional restart: unless-stopped deploy: mode: global resources: limits: cpus: \u0026#39;20\u0026#39; memory: 8G qbittorrent qbittorrent 是用于 bt 下载的软件。linuxserver.io 也打包了 qbittorrent 的镜像，使用这个镜像运行即可。我的docker-compose.yaml如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 services: qbittorrent: image: lscr.io/linuxserver/qbittorrent:latest container_name: qbittorrent environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - WEBUI_PORT=4823 volumes: - ./config:/config - ./torrents:/torrents - ./cache:/cache - /path/to/downloads:/downloads ports: - 4823:4823 # WebUI - 6881:6881 # 监听端口 - 6881:6881/udp - 14560-14580:14560-14580 # 传出端口 - 14560-14580:14560-14580/udp restart: unless-stopped deploy: mode: global resources: limits: cpus: \u0026#39;2.0\u0026#39; memory: 1G frpc 内网穿透工具的客户端，我用的是下载量最高的镜像。\ncoredns DNS 服务器，因为学校的 DNS 以前崩过，所以装一个备用。官方镜像即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 services: coredns: image: coredns/coredns:latest container_name: coredns volumes: - ./config:/config command: [\u0026#34;-conf\u0026#34;, \u0026#34;/config/Corefile\u0026#34;] restart: always ports: - 0.0.0.0:53:53 - 0.0.0.0:53:53/udp deploy: mode: global resources: limits: cpus: \u0026#39;0.5\u0026#39; memory: 100M 53 端口可能和 ubuntu 的 systemd-resolved 服务冲突，在启动容器前需要先关闭这个服务：\n1 2 $ sudo systemctl disable systemd-resolved $ sudo systemctl stop systemd-resolved coredns 结合 nginx/Apache 转发与一些路由器的设置就可以实现内网域名（不用记端口号了），例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ### Corefile: ...... server.local { hosts { 192.168.0.xx jellyfin.server.local } log errors prometheus } ### nginx config: server { listen 80; server_name jellyfin.server.local; location / { proxy_pass http://127.0.0.1:8096; } } 这样在局域网直接访问 http://jellyfin.server.local 就可以进入 jellyfin 的界面了。\n注：关闭 systemd-resolved 服务之后在使用 KVM 时可能会遇到一些问题。\nGrafana \u0026amp; Prometheus Grafana 和 Prometheus 这两个开源软件组合在一起可以用来监控服务器状态（不过在自用的 NAS 上搞这个可能意义不大）。之前没了解过这些软件，因此这部分完全是按照教程安装的，其中 Grafana 不涉及数据收集，可以在 Docker 容器中运行。\n除了这两个软件，我还安装了 node exporter 和 cadvisor，分别收集服务器系统与 Docker 容器的统计信息。\n装好之后，我以 node exporter 为基础改出了这样的 dashboard： 数据库 有一些服务（例如 gitea 和自己写的爬虫）的数据是存储在数据库中的，我比较喜欢将这些数据放在同一个数据库服务端内（而非给每个有需要的应用都运行一个数据库），以便于数据的管理，同时减少系统占用。\n关于关系型数据库，我使用的是 mariadb（MySQL的一个衍生版本）。关于镜像的版本，建议使用一个固定的版本号（而非 latest），因为在不同版本的 mariadb 之间迁移数据还是比较麻烦的。\n关于数据库的管理端，我以前常用的是 phpmyadmin，这次想试试别的，所以使用了 官方docker镜像页 里提到的 adminer。其功能虽不如 phpmyadmin 丰富，界面也不如它美观，但是我平时会用到的基础操作（建表、查看数据、SQL 查询、导出数据）它都有，缺少的功能可以直接用 SQL 语句凑嘛~\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 services: db: image: mariadb:10.11.4 container_name: mariadb restart: always environment: MARIADB_ROOT_PASSWORD: ... volumes: - ./mariadb:/var/lib/mysql ports: - 3306:3306 adminer: image: adminer container_name: adminer restart: always ports: - 8080:8080 如果服务需要，也可以使用 docker 运行非关系型数据库 MongoDB 和 redis。\nMinecraft 服务器 （papermc） 选了 docker hub 里搜索排名靠前的 marctv/minecraft-papermc-server。\n用了之后才发现，papermc 是 SpigotMC 的分支，旨在提供原生 Minecraft 的体验。也就是说它不支持以前我在玩 Minecraft 时耳熟能详的那些 Forge 版 mod，只支持服务器端的 bukkit 插件（plugin）。好处是相比与 Forge 服务器占用更小，并且不挑客户端，只要客户端 Minecraft 版本和服务器一致就能连上。 配置好之后，使用 frpc 转发 25565 端口到公网，就可以愉快地和朋友们一起玩啦。\n后台管理 在 docker-compose.yaml 中对应的 service 配置里加上\n1 2 3 stdin_open: true tty: true container_name: mcserver 然后\n1 $ docker compose up -d 之后便可以通过\n1 $ docker attach mcserver 进入服务器后台，使用指令管理服务器。\n配置 papermc 相比于原版服务端修复了活塞相关的一些“特性”，例如使用活塞复制物品等，并在配置文件中默认限制这些行为，导致刷地毯机/破基岩等原版可行的操作在 papermc 服务端内不可用。当然这样对于服主而言确实可以防止玩家做出越界的行为，但是对于我这种只有几个朋友在一起玩的服务器，就不需要限制这些了。关闭限制的方式很简单，修改数据目录下的paper.yml，将allow-headless-pistons、allow-permanent-block-break-exploits和allow-piston-duplication三项设置为true即可。\n安装插件 Papermc 支持的插件可以在 Hanger、bukkit或SpigotMC下载。下载对应版本的 jar 文件放到 /data/plugins 文件夹下（或者直接使用 wget/curl 下载），然后重启服务器，在启动时如果新增的插件没有报错误信息，那大概率是没问题的。\n目前加了这些插件：\nMinepacks：背包插件； TreeFeller：连锁砍树； worldedit：创世神插件； worldguard EssentialsX：正如其名，提供一些服务器的必备功能； StackableItems：增加物品堆叠上限； Multiverse-Core：多世界基础插件。 Multiverse-signportals：使用告示牌在多世界间传送； OpenTerrainGenerator：创建不同类型世界的基础插件之一。 Skylands FarFromHome ViaVersion：放宽客户端版本限制； LaggRemover：减少服务器卡顿； BlueMap: 地图插件，提供了美观的在线3D地图； UnifiedMetrics：数据收集插件，支持前述的 Prometheus。 参考资料 [1] Install Docker Engine on Ubuntu - Docker Docs | https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script⤶ [2] Docker 换源 - 腾讯云开发者社区 | https://cloud.tencent.com/developer/article/1769231⤶ ","date":"2023-06-18T13:58:40+08:00","image":"https://files.furffisite.link/blogimg/20230618181015-7e414fb06bb70924b269f0ca2a5ba8f6-28296.jpg","permalink":"https://blog.furffisite.link/p/nas-3/","title":"我折腾 NAS 的历程（三）：捡垃圾自组"},{"content":"算法 Q 学习算法（Q-Learning Algorithm）的思路比较简单：使用 Q 函数记录每一个状态下每一个动作（action）的期望最大总回报（reward），即 Q 值。在推理时贪心地选择当前状态 Q 值最大的动作，从而达到最大化期望总回报的目的。当问题的状态与动作均为离散时，Q 函数可以使用表格记录，这个表格也称为 Q 表格（Q-Table）。\n设：\n问题的状态空间为 $S = {1,2,\\ldots, m}$； 问题的动作空间为 $A = {1,2,\\ldots, n}$； 探索阈值为 $\\epsilon\\in [0,1]$（推理时 $\\epsilon = 0$）； 学习率 $\\eta\\in [0,1]$； 回报衰减率 $\\gamma\\in [0,1]$。 则 Q 学习算法的流程如下：\n初始化 Q 表格为零矩阵 $Q=O_{m\\times n}$； 设初始时间 $t = 0$，状态为 $s_t = s_0$； 选择动作 $a_t$：取随机数 $r\\in[0,1]$，若 $r\u0026lt;\\epsilon$，则当前为探索阶段，从 $A$ 随机选取一个动作；否则 $a_t = \\argmax_{j\\in A} Q_{s_t, j}$； 与环境交互，执行动作 $a_t$，并获得状态 $s_{t+1}$、回报 $r_t$； 按照 Bellman 方程 更新Q表格： $$Q_{s_t, a_t} \\leftarrow (1-\\eta) Q_{s_t, a_t} + \\eta(\\gamma\\max_{j\\in A} Q_{s_{t+1},j} + r_t),$$ 其中 $\\max Q_{s_{t+1},j}$ 为 转移后的状态 $s_{t+1}$ 下最大的Q值，加上 $r_t$，组成转移前状态 $s_t$ 下 $a_t$ 操作的Q值。将其与原来的 $Q_{s_t, a_t}$ 加权平均就得到了更新后的Q值。 时间 $t\\leftarrow t+1$，回到第 3 步。 实现 Frozen Lake 以 Gym 的 Frozen Lake 环境为例，其状态空间与动作空间都是离散的，因此适合使用 Q 表格。这个环境共有 $4^2=16$ 种状态，4 种动作，分别对应上下左右四个移动方向。环境中slippery引入的不确定性太大（每次行动只有$1/3$的概率能真正前往指定的方向），因此这里创建环境时is_slippery一项设为False。\n实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import gymnasium as gym import numpy as np from random import random env = gym.make(\u0026#39;FrozenLake-v1\u0026#39;, map_name=\u0026#34;4x4\u0026#34;, is_slippery = False) n_actions, n_states = env.action_space.n, env.observation_space.n lr, gamma = 0.2, 0.6 total = 1000 Q_table = np.zeros((n_states, n_actions)) state, info = env.reset() for t in range(total): # 选择动作 epsilon = 1 - t / total if random() \u0026lt; epsilon: # 探索 action = env.action_space.sample() else: action = Q_table[state].argmax(0) org_state = state state, reward, terminated, truncated, info = env.step(action) if state == n_states-1: # 抵达终点，获得奖励 reward = 20 elif terminated: # 掉进洞里，给予惩罚 reward = -5 else: # 让agent尽快抵达终点 reward = -1 # 更新Q值 Q_table[org_state, action] = ((1 - lr) * Q_table[org_state, action] + lr * (reward + gamma * Q_table[state].max())) if terminated or truncated: state, info = env.reset() 原环境提供的回报函数所含的信息较少（仅在抵达终点时为 1，其余情况均为 0），不利于算法的收敛，因此我在实现中重新设计了回报函数。 此外，训练时采用线性衰减的探索阈值 $\\epsilon$ ，即训练初期倾向于探索（exploration），后期倾向于开发（exploitation）。\n训练时每轮的 t 与该轮获得的总 reward 的折线图如下：\n推理时算法选择的路线如下图，确实是最优路线之一。\n除了 Frozen Lake，这个方法也可以用来求解 Gym 提供的 Cliff Walking、Taxi 与 Blackjack。但是，随着问题规模的增大，训练步数也需要相应地增加。\nCliff Walking 这个环境有 48 种状态和 4 种动作，因此 Q 表格内共有192项。以下是训练了 10,000 步的结果（平均每项 52 步）：\nTaxi 这个环境有 500 种状态和 6 种动作，对应 Q 表格的 3000 项。以下是训练了 200,000 步的结果（平均每项 67 步）：\nBlackjack Blackjack 有 $32\\times 11\\times 2=704$ 种状态和 $2$ 种动作，在处理时需要将离散的状态向量映射到非负整数域内。 这个游戏的状态转移存在不确定性，即使是充分训练（$5\\times 10^6$ 步）的Q表格也只能将胜率从完全随机时的 28.2% 提升到 39.3%。\n分析 优点 算法简单，易于理解和实现。 局限性 基于 Q 表格的 Q 学习算法只能处理输入输出都是离散的问题； 基于 Q 表格的 Q 学习算法不能跨实例学习，即在遇到新的问题实例时，需要从 0 开始重新探索； 基于 Q 表格的 Q 学习算法难以处理训练过程中没有见过的状态； 当状态空间或动作空间很大时，Q 表格的规模也会很大，从而需要更长的学习时间。 上述问题可以通过引入神经网络缓解，即深度 Q 学习算法（Deep Q-Learning Algorithm）。\n","date":"2023-05-18T15:05:05+08:00","image":"https://files.furffisite.link/blogimg/20230518191643-b6c8849bfb006d40abef7203bb5e15a0-18b9a.jpg","permalink":"https://blog.furffisite.link/p/q-learning/","title":"【RL学习笔记】Q学习算法"},{"content":"因为 Linux 端的 Zotero（AUR）中有一部分元素的样式是由 GTK 控制的，因此当系统的 GTK 主题为深色主题时，Zotero 的界面会呈现为这个样子： 这不是很好看，并且部分区域内文字和背景色的对比度很低，导致文字难以阅读。\n根据这个帖子，解决方案是通过环境变量在程序启动时指定其使用的 GTK 主题，也就是：\n1 $ GTK_THEME=Pop-light zotero 反映到 Desktop 文件上（通常位于/usr/share/applications/和~/.local/share/applications/），就是在启动指令（Exec 项）前加入env GTK_THEME=Pop-light。\n1 2 3 4 5 [Desktop Entry] Type=Application Name=Zotero Exec=env GTK_THEME=Pop-light /usr/bin/zotero -url %U ... 这样操作后，通过应用启动器打开的 Zotero 就不会有问题了。\n","date":"2023-05-13T13:12:27+08:00","image":"https://files.furffisite.link/blogimg/20240527150719-58fa3bf91a709e8e208c96720f0aeca2-547a4.jpg","permalink":"https://blog.furffisite.link/p/linux-darkmode-zotero-gui-issue/","title":"解决 Linux 系统深色模式下的 Zotero 显示问题"},{"content":"问题背景 在使用 Python 的 Flask 框架开发 Web 应用的过程中，一个基本的服务端程序结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from flask import Flask app = Flask(__name__) @app.route(\u0026#39;/handler1\u0026#39;) def handler1(): ... @app.route(\u0026#39;/handler2\u0026#39;) def handler2(): ... @app.route(\u0026#39;/handler3\u0026#39;) def handler3(): ... 可以按照这种模式无限添加处理视图（handler），但是随着项目增大，这种将所有 handler 都放在一个 py 文件里的模式显然是不合适的，这时可以使用 blueprint 将每个 handler（或一组 handler）放在互相独立的文件里。\n项目结构如下：\n1 2 3 4 5 6 7 . ├── app.py └── services ├── __init__.py ├── login.py ├── register.py ... 代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026#34;\u0026#34;\u0026#34; === app.py === \u0026#34;\u0026#34;\u0026#34; from flask import Flask from services import blueprint app = Flask(__name__) app.register_blueprint(blueprint) \u0026#34;\u0026#34;\u0026#34; === services/__init__.py === \u0026#34;\u0026#34;\u0026#34; from flask import Blueprint blueprint = Blueprint(\u0026#39;api\u0026#39;, __name__) # 为了在程序启动过程中能运行两个 handler 文件，需要在这里 import 它们 from . import login from . import register \u0026#34;\u0026#34;\u0026#34; === services/login.py === \u0026#34;\u0026#34;\u0026#34; from . import blueprint @blueprint.route(\u0026#34;/login\u0026#34;) def handle_login(): # 处理登录逻辑 ... \u0026#34;\u0026#34;\u0026#34; === services/register.py === \u0026#34;\u0026#34;\u0026#34; from . import blueprint @blueprint.route(\u0026#34;/register\u0026#34;, methods=[\u0026#34;POST\u0026#34;]) def handle_register(): # 处理注册逻辑 ... 这样做存在两个问题：\n每次新增一个文件都需要在__init__.py中添加相应的 import 语句，较为麻烦； PEP-8 中要求将 import 语句放在文件的顶部，__init__.py显然不符合（但必须如此），因而静态检查器有可能在此处报错（E402）。 于是就自然而然地想到了：如何在模块初始化时自动导入当前路径下的所有子模块呢？\n解决方法 将services/__init__.py改为这样：\n1 2 3 4 5 6 7 8 import pkgutil import importlib from flask import Blueprint blueprint = Blueprint(\u0026#39;api\u0026#39;, __name__) for spec in pkgutil.iter_modules(path=__path__, prefix=\u0026#39;\u0026#39;): importlib.import_module(\u0026#34;.\u0026#34;+spec.name, __name__) 原理探究 可以通过 pdb 或 print 获得这段程序所涉及变量的值：\n1 2 3 4 __name__ = \u0026#39;services\u0026#39; __path__ = [\u0026#39;/tmp/test/services\u0026#39;] spec = ModuleInfo(module_finder=FileFinder(\u0026#39;/tmp/test/services\u0026#39;), name=\u0026#39;login\u0026#39;, ispkg=False) spec = ModuleInfo(module_finder=FileFinder(\u0026#39;/tmp/test/services\u0026#39;), name=\u0026#39;register\u0026#39;, ispkg=False) 其中__name__为当前包的名字，__path__为文件所在文件夹的路径。 pkgutil模块的iter_modules函数会找到提供的path下的所有子模块，在这里就是login与register，并返回它们的 ModuleInfo。\n在 for 循环内提取 ModuleInfo 的 name，得到模块的名字，加上前缀.，即当前目录下的对应子模块。 最后使用 importlib 的 import_module 函数导入子模块（即运行子模块的代码，将 handler 注册到 router 上）。这样无论增加多少 handler 文件，__init__.py 都可以找到并加载它们。\n","date":"2023-05-11T12:22:54+08:00","image":"https://files.furffisite.link/blogimg/20230511163144-c5d0b19ce502665b1891ef8c78c5b839-32aa3.jpg","permalink":"https://blog.furffisite.link/p/python-import-directory-modules/","title":"在Python中导入当前路径下的所有模块"},{"content":"starship 是使用 Rust 编写的轻量且迅速的终端提示符程序，其功能和作用与 Oh My Zsh 相似，但是相比于 Oh My Zsh，starship 具有以下优点：\nstarship 是跨平台跨终端的，其支持 Bash、Zsh、Fish 等十几种终端，甚至包括 Windows 的 PowerShell 与 cmd； 使用编译型语言 Rust 编写的 starship 在运行速度上优于基于 shell script 的 Oh My Zsh； starship 的自定义配置方法比 Oh My Zsh 简单。 先上图，以下是我所习惯的配置的效果图。除当前用户、hostname 和当前工作路径外，starship 还显示了 git 状态、相关软件的版本、进程的返回码、运行时间、已用内存/虚拟内存和当前时间等信息。starfish 是通过当前工作目录下的文件名判断应当展示哪些模组的，所以当我创建文件之后提示符上也就多出了相关软件的信息。\n下文将简述 starship 的安装方法，并给出我的配置文件。\n安装 本文仅适用于在 Linux 下的 bash 和 zsh 终端安装 starship，在其它终端的安装方法请参见 starship 的官方文档。\n首先使用官方脚本在 Linux 系统内安装 starship 程序：\n1 $ curl -sS https://starship.rs/install.sh | sh 这时如果在终端输入starship -V能看到 starship 的版本信息，就说明程序安装成功了。\n然后需要配置终端程序，使其能使用 starship 作为提示符。在~/.bashrc（bash 终端）或~/.zshrc（zsh 终端）内加入这一行即可：\n1 eval \u0026#34;$(starship init bash)\u0026#34; 配置 starship的配置文件是~/.config/starship.toml，你也可以通过设置环境变量STARSHIP_CONFIG改变此文件的位置。在终端输入starship config可以直接打开该文件。\n由后缀名可知，starship 的配置文件为 TOML 文件，遵守 TOML 语法，关于 TOML 语法本文就不赘述了，若需要了解详情请移步 TOML 官网。\nstarship 是分模块的结构，starship 生成的提示符中的每一个部分都对应 starship 的一个模块，你可以使用starship explain指令查看各模块的说明及其运行时间，例如以我当前的配置输入该命令后效果如下：\n关于如何自定义配置，starship 的官方文档已经写的很完善了，参见 https://starship.rs/zh-CN/config/。\nstarship 在官方文档里已经给出了一些预设，你可以以你喜欢的预设为基础进行定制，例如我的配置就是在 Bracketed Segments 和 Nerd Font Symbols 预设之上按照自己的习惯所做的更改。我的starship.toml如下：\n另外，使用 Nerd Font Symbols 需要 Nerd Font，请前往 https://www.nerdfonts.com/font-downloads 下载你习惯的字体对应的图标字体，并在虚拟终端中将其设为默认字体。\n相关问题 在使用 Anaconda 管理 Python 的虚拟环境时，Anaconda 会自动在提示符前加上当前虚拟环境的名称，如(base)，这与 starship 冲突了（且 starship 的 conda 模块提供了相同的功能），因此需要使用如下指令禁用 Anaconda 的这个功能。\n1 $ conda config --set changeps1 False ","date":"2023-01-06T16:24:31+08:00","image":"https://files.furffisite.link/blogimg/20230109230402-9ec5accbc75f863015a4dca68f9f9870-cc3be.jpg","permalink":"https://blog.furffisite.link/p/use-starship/","title":"使用starship定制终端提示符"},{"content":" 今天在 QQ 看到一张图，这张图在预览下看到的和查看图片时看到的内容不一样。虽然不是第一次见这种图了，但是今天在摸鱼的时候无事可做，就研究了一下它的原理。\n这张图是这样的：左图为它在聊天界面的样子，典型的吃桃场景，点开大图之后看到的却是右图的样子（笑）。 中间的图片为嵌入的原图，如果您开启了暗色模式（桌面端可以在页面左下角切换），您看到中图的应该和右图一样，反之则和左图一样。 原图可以在这里获取。\n原理 这种图的原理并不难猜，肯定利用了 png 图片的透明度通道，使其在不同背景色下能呈现出不同的效果。下面求解一下它是怎么制作出来的： （因为这里只涉及图像的像素变换，为简化表示，以下的每个变量都表示单个像素单个通道的值，且定义域为$[0,1]$.）\n设在聊天界面看到的图像（表图）灰度为$c$，点开大图后看到的图像（里图）为$h$，待求量为生成的图像的灰度$g$与透明度$a$。\n在聊天界面的图像是目标图像和白色背景的混合，也就是$$(1-a) + g\\cdot a = c.$$ 点开大图后是目标图像和黑色背景的混合，即$$0+g\\cdot a = h.$$\n解出来就是$$a=1+h-c,~g=h/a.$$\n又因为解需要满足$a,g\\in(0,1]$，所以$c$和$h$需要满足不等式$$h\\le c\u0026lt;1+h$$ 右侧当且仅当$c=1,~h=0$时不成立。\n实现 这个程序实现起来没有什么难度，python 代码如下（需要 Pillow 与 numpy）。需要注意的是，为了满足上面的不等式，在程序中需要重新分配两张原图的灰度的范围。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import numpy as np from PIL import Image # 读取图片+转灰度 cover = Image.open(\u0026#34;./cover.png\u0026#34;).convert(\u0026#34;L\u0026#34;) hidden = Image.open(\u0026#34;./hidden.png\u0026#34;).convert(\u0026#34;L\u0026#34;) assert cover.size == hidden.size cover = np.asarray(cover) hidden = np.asarray(hidden) # 按照约束条件调整像素范围 cover_min, cover_max = cover.min(), cover.max() hidden_min, hidden_max = hidden.min(), hidden.max() cd = cover_max - cover_min hd = hidden_max - hidden_min divide_portion = hd/(hd*1.0+cd) cover_f = (cover-cover_min)*1.0/cd * (1-divide_portion-1/255) + divide_portion hidden_f = (hidden-hidden_min)*1.0/hd * divide_portion # 计算 alpha = 1-cover_f+hidden_f gray = hidden_f/alpha alpha = (alpha*255).astype(np.uint8) gray = (gray*255).astype(np.uint8) result = np.stack([gray,gray,gray,alpha], axis=-1) # 保存结果 img = Image.fromarray(result) img.save(\u0026#34;./output.png\u0026#34;) 这是随手抓的两张黑白表情包做出来的效果，顺序和上面的展示一样，您可以通过切换暗色模式查看效果：\n注：在 QQ 发送此类图片时，一定要选择发送原图，否则 QQ 可能会在压缩过程中去掉透明度通道，导致其失效。\n","date":"2023-01-03T23:51:54+08:00","image":"https://files.furffisite.link/blogimg/20230104022542-b692e6e89157626a929575a0b97e5583-3e819.jpg","permalink":"https://blog.furffisite.link/p/qq-duplicity-image/","title":"利用透明度通道制作 QQ 内表里不一的图片"},{"content":"如何在$\\LaTeX$中将超出文本宽度的浮动体（表格/图片）居中？这个问题我曾多次遇到过，但是没有一次记得怎么解决，每次都需要谷歌。今天也碰到了这个情况，因此将解决方案记录备忘。\n我看到的最优雅的解决方案出自 $\\TeX$ 的 StackExchange 中的这篇回答。只要在浮动体内减少左右边距即可，也就是下列示例的第 3-4 行：\n1 2 3 4 5 6 7 \\begin{figure}[t] \\centering \\addtolength{\\leftskip}{-2cm} % increase (absolute) value if needed \\addtolength{\\rightskip}{-2cm} \\includegraphics[width=1.2\\textwidth]{image} \\caption{example}\\label{fig:example} \\end{figure} 效果如下图：\n","date":"2022-12-24T12:38:21+08:00","image":"https://files.furffisite.link/blogimg/20230511163659-9e52e93f3d72fae5e3a97613e49e921f-97fa4.jpg","permalink":"https://blog.furffisite.link/p/latex-widefloat-centering/","title":"如何将LaTeX内超出文本宽度的浮动体居中"},{"content":"前言 今天想给我这个博客加一张图片，但是把图片文件和博客的文章放在一起，内容管理比较麻烦，并且会增大 git 仓库的体积。因此我就想到了使用图床分流博客中的图片。\n在网上搜索了一些图床服务，发现国内免费的图床服务要么访问慢（因为源服务器在海外），要么不稳定（存在关站/被墙或者转为付费的可能），而国外著名的图床 imgur 在国内也处于半墙的状态。于是就想到了使用云计算厂商提供的 OSS 对象存储服务，虽然收费但是对于我这种有计划长时间运营下去的博客而言，图床的可靠性是最重要的。我可不想因为图站挂掉导致我在未来的某一天要重新找到再上传这些图片。\n在看了阿里云、腾讯云和华为云三家之后我选择了阿里云，因为阿里云有每月 5GB 存储和外网流量的的免费额度，请求费用也就每万次一毛钱，对于我这种刚开的小站而言，存储、流量和请求都不会很大（如果被攻击那就是另一回事了，还望您手下留情）。关于阿里云的定价详情可以查看阿里云的价格计算器。\n然后我就按照这篇博文的步骤搭建了图床，途中遇到了原文没有提及的许多问题，所以在这里记录一下完整的步骤、我遇到的问题与解决方案。\n主要操作流程 创建Bucket：开通 OSS 并创建 Bucket。创建 Bucket 时选择海外的地域（如果在别的地域没有服务器的话，建议使用香港），存储类型选择标准存储即可，读写权限一定要选择私有，其余的附加服务按需启用（有的得加钱）。创建完成后可以向 Bucket 中上传一张图片作为测试图。\n配置访问权限：进入权限控制 -\u0026gt; Bucket 授权策略面板，添加授权，配置如下图。\nIP 字段填写的是 CloudFlare 的节点 IP，列表如下（来自知乎专栏）：\n173.245.48.0/20,103.21.244.0/22,103.22.200.0/22,103.31.4.0/22, 141.101.64.0/18,108.162.192.0/18,190.93.240.0/20,188.114.96.0/20, 197.234.240.0/22,198.41.128.0/17,162.158.0.0/15,104.16.0.0/12, 172.64.0.0/13,131.0.72.0/22,103.21.244.0/22,103.22.200.0/22, 103.31.4.0/22,104.16.0.0/12,108.162.192.0/18,131.0.72.0/22, 141.101.64.0/18,162.158.0.0/15,172.64.0.0/13,173.245.48.0/20, 188.114.96.0/20,190.93.240.0/20,197.234.240.0/22,198.41.128.0/17 配置 CDN：在 CloudFlare 的 DNS 管理面板添加 CNAME 记录，目标设为 Bucket 的域名（可以在 Bucket 的概览界面找到），代理状态设为已代理，否则 CDN 不起作用。 绑定域名：在阿里云的 Bucket 配置 -\u0026gt; 域名管理界面绑定你刚设置的域名，这时阿里云需要验证域名的所有权，按照其所说的在 CloudFlare 的 DNS 管理处添加指定 TXT 记录即可。\n创建并添加证书：在 CloudFlare 的配置面板的 SSL/TLS -\u0026gt; 源服务器处，选择创建证书。创建之后会告诉你源证书与私钥，这个界面暂时不要动。打开刚才在阿里云控制台绑定证书的界面，选择证书托管，并上传 SSL 证书，这时会打开SSL 证书的界面，选择上传证书，并将 CloudFlare 给出的源证书和密钥复制到上传证书的对应字段处（证书名字随便设），然后确定。这时切换回上传 SSL 证书，应该就能在证书名称处看到刚刚设置的证书名字了（看不到的话重开一下这个界面试试），选中，然后点下方的上传即可。\n这时就已经可以通过你设置的域名访问刚才上传的测试图片了。假如测试图片filename.jpg存储在 OSS 的folder文件夹下，你设置的域名为image.example.org，则访问路径为https://image.example.org/folder/filename.jpg。\n安全性配置 跨域设置：在阿里云 OSS 的数据安全 -\u0026gt; 跨域设置中创建跨域规则，来源设置为你的网站的地址。为了能让网站在本地测试时也能正常展示图片，建议同时添加localhost:*与127.0.0.1:*。 防盗链设置：和跨域设置类似。不同之处在于 Referer 是包含请求协议的，所以类似于example.org或localhost:*等不包括协议的配置是无效的，需要改为https://example.com或*://localhost:*；需要注意的是*.example.org虽然是有效的，但是没有指定 https 协议，安全起见最好改为https://*.example.org。 PicGo 配置 PicGo 是一款快速上传图片到图床，并自动复制图片URL到剪贴板的工具，你可以在 Github 的 release 页获取该程序。\n权限设置：在阿里云的权限控制 -\u0026gt; Bucket 授权策略面板新增授权，配置如下： 如果当前没有RAM子帐号，请点击右上角头像 -\u0026gt; 访问控制，然后在左侧的身份管理 -\u0026gt; 用户处创建一个子帐号。创建完成后在子帐号的详情页创建 AccessKey，得到 AccessKey 的 KeyID 与KeySecret，保留备用。\n上传配置：打开 PicGo 主界面，在图床设置 -\u0026gt; 阿里云 OSS 内填写对应的表单项。“KeyID” 与 “KeySecret” 即刚才获取的子帐号 AccessKey 的 KeyID 与 KeySecret，“设定 Bucket”为 Bucket 的名称，“存储区域”为 Bucket 所在区域（与 Bucket 域名内的值统一，例如oss-cn-hongkong），自定义域名填写你设置的域名，其余两项按需填写即可。配置完成后点击确定并设为默认图床。\n注：如果你使用的桌面环境是 KDE Plasma，可能需要在 PicGo 设置内打开“使用内置剪贴板上传”一项，否则无法正常从剪贴板直接上传图片。我使用的 Linux 发行版是 KDE Neon，其它发行版/桌面环境/操作系统尚未测试。\n","date":"2022-12-20T01:48:09+08:00","image":"https://files.furffisite.link/blogimg/202212251307965.jpg","permalink":"https://blog.furffisite.link/p/imagebed-oss-conf/","title":"使用阿里云 OSS 存储服务 + CloudFlare 配置图床"}]